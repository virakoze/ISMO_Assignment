{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "\n",
    "\n",
    "class Production_data:\n",
    "    def __init__(self, number_of_periods, number_of_items, demand_forecast, production_cost, holding_cost, setup_cost, item_requirements , capacity):\n",
    "        self.T=number_of_periods\n",
    "        self.items=number_of_items\n",
    "        self.demand_forecast=np.array(demand_forecast)\n",
    "        self.production_cost=np.array(production_cost)\n",
    "        self.holding_cost=np.array(holding_cost)\n",
    "        self.setup_cost=np.array(setup_cost)\n",
    "        self.item_requirements=np.array(item_requirements)\n",
    "        self.capacity=np.array(capacity)\n",
    "\n",
    "file_name = \"CLSP+ST-instances Data-R.xlsx\"\n",
    "#file_name = \"prova2.xlsx\"\n",
    "\n",
    "xls = pd.ExcelFile(file_name)  # Read the whole file\n",
    "\n",
    "tables_keywords = [\"Demand Forecast:\", \"Production Cost\", \"Holding Cost\", \"Setup Cost\", \"UnitsOfCapacity\", \"Capacity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(xls, sheet_name):\n",
    "    tables_dict = {}\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    \n",
    "    # Define which column to check for each keyword\n",
    "    columns_to_check = {\n",
    "        \"Demand Forecast:\": 0,\n",
    "        \"Production Cost\": 0,\n",
    "        \"Holding Cost\": 0,\n",
    "        \"Setup Cost\": 0,\n",
    "        \"UnitsOfCapacity\": 1,  # Check the second column for this keyword (it also contains setup time(i,2))\n",
    "        \"Capacity\": 0\n",
    "    }\n",
    "    \n",
    "    # Iterate through the keywords to find each table\n",
    "    for keyword in tables_keywords:\n",
    "        column_idx = columns_to_check.get(keyword, 0)\n",
    "        \n",
    "        # Check in the specified column for the keyword\n",
    "        match = df[df.iloc[:, column_idx].astype(str).str.contains(keyword, na=False)]\n",
    "        \n",
    "        if not match.empty:\n",
    "            table_start_row = match.index[0] + 1\n",
    "            \n",
    "            # Find the end of the current table (next keyword or empty rows)\n",
    "            end_row = None\n",
    "            for next_keyword in tables_keywords:\n",
    "                if next_keyword != keyword:\n",
    "                    next_column_idx = columns_to_check.get(next_keyword, 0)\n",
    "                    next_match = df.loc[table_start_row:][df.loc[table_start_row:].iloc[:, next_column_idx].astype(str).str.contains(next_keyword, na=False)]\n",
    "                    if not next_match.empty:\n",
    "                        potential_end = next_match.index[0]\n",
    "                        if end_row is None or potential_end < end_row:\n",
    "                            end_row = potential_end\n",
    "            \n",
    "            # If no next keyword found, look for empty rows\n",
    "            if end_row is None:\n",
    "                for i in range(table_start_row, len(df)):\n",
    "                    # Check if row is empty or contains only NaN values\n",
    "                    if df.iloc[i].isna().all():\n",
    "                        end_row = i\n",
    "                        break\n",
    "            \n",
    "            # If still no end found, use the end of the dataframe\n",
    "            if end_row is None:\n",
    "                end_row = len(df)\n",
    "            \n",
    "            # Extract the table\n",
    "            table_df = df.iloc[table_start_row:end_row]\n",
    "            \n",
    "            # Remove completely empty rows\n",
    "            table_df = table_df.dropna(how='all')\n",
    "            \n",
    "            # Remove completely empty columns\n",
    "            table_df = table_df.dropna(axis=1, how='all')\n",
    "            \n",
    "            # Remove any remaining NaN values by filling with 0\n",
    "            table_df = table_df.fillna(0)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            table = table_df.to_numpy()\n",
    "            tables_dict[keyword] = table\n",
    "    \n",
    "    # Create an instance of Production_data class\n",
    "    production_data = Production_data(\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[1]-1,\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[0]-1,  \n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Production Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Holding Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Setup Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"UnitsOfCapacity\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Capacity\", np.zeros((1,1)))\n",
    "\n",
    "    )\n",
    "    \n",
    "    production_data.capacity = np.vstack([\n",
    "    np.zeros((1, production_data.capacity.shape[1]), dtype=production_data.capacity.dtype),production_data.capacity])\n",
    "\n",
    "    production_data.item_requirements = np.vstack([\n",
    "    np.zeros((1, production_data.item_requirements.shape[1]), dtype=production_data.item_requirements.dtype),production_data.item_requirements\n",
    "])\n",
    "    return production_data \n",
    "\n",
    "#data=read_data(xls, \"Data-20-12 (1)\")\n",
    "\n",
    "#print(data.T)\n",
    "#print(data.items)\n",
    "\n",
    "#print(data.demand_forecast)\n",
    "#print(data.holding_cost)\n",
    "#print(data.setup_cost)\n",
    "#print(data.capacity)\n",
    "#print(data.production_cost)\n",
    "\n",
    "#print(data.capacity[0, 1])\n",
    "#print(data.capacity[12, 1])\n",
    "#print(data.item_requirements)\n",
    "\n",
    "sheet_list=[\"Data-20-12 (2)\"]#, \"Data-20-12 (2)\", \"Data-20-24 (1)\", \"Data-20-24 (2)\" , \"Data-100-24 (1)\", \"Data-100-24 (2)\",\n",
    "          #  \"Data-200-24\" ]\n",
    "\n",
    "#sheet_list=[\"Sheet1\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "\n",
    "def solve_MILP(data, sheet_name, results_df):\n",
    "\n",
    "    model=gp.Model(\"MiCLSP-ST\")\n",
    "\n",
    "    T=data.T\n",
    "    O=data.items\n",
    "\n",
    "    #DUMMY AT PERIOD 0?\n",
    "\n",
    "    #decision variables, constraint 5 and 6 added here\n",
    "    y=model.addVars(O+1, T+1, vtype=GRB.BINARY, name=\"y\" ) #produce of not for this item in this period\n",
    "    s=model.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"s\") #amount of inv of item i in period t\n",
    "    x=model.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"x\") #amount produced of item i in period t\n",
    "\n",
    "    model.setObjective(\n",
    "        quicksum(quicksum( data.setup_cost[i, t] * y[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        quicksum(quicksum( data.production_cost[i, t] * x[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        quicksum(quicksum( data.holding_cost[i, t] * s[i, t] for i in range(1, O+1) ) for t in range(1, T+1)),\n",
    "        GRB.MINIMIZE\n",
    "    )  \n",
    "\n",
    "\n",
    "    #constraint 2\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr(s[i, t-1]+x[i, t]-s[i, t]==data.demand_forecast[i, t])\n",
    "\n",
    "    \n",
    "\n",
    "    #constraint 3, this definitely works\n",
    "    for t in range(1, T+1):\n",
    "        print(data.capacity[t,1])\n",
    "        model.addConstr( quicksum( x[i, t]*data.item_requirements[i, 1] + data.item_requirements[i,2] * y[i,t] for i in range(1, O+1))<= data.capacity[t, 1])\n",
    "        \n",
    "    #constraint 4, this defintely ok\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr(x[i, t]-(quicksum(data.demand_forecast[i, q] for q in range(t, T+1))) * y[i, t]<=0)\n",
    "\n",
    "    #constraint 7, no initial inventory for all items, this definitely works\n",
    "    for i in range(1, O+1):\n",
    "        model.addConstr( s[i, 0] == 0, name=\"no init inv\") #lloks like this constrint is ok\n",
    "    \n",
    "    #solve the model\n",
    "    model.optimize()\n",
    "\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        print(\"\\noptimal solution found:\")\n",
    "        print(model.ObjVal)\n",
    "\n",
    "        # Create a list to store all periods' results for this sheet\n",
    "        period_results = []\n",
    "        \n",
    "        # Collect results for each period\n",
    "        for t in range(1, T+1):\n",
    "            period_results.append({\n",
    "                \"Sheet\": sheet_name,\n",
    "                \"Period\": t,\n",
    "                \"Inventory of item 1\": s[3, t].X,   # hard-coded for item 1 only\n",
    "                \"Produced for item 1\": x[3, t].X\n",
    "            })\n",
    "        \n",
    "        # Add all periods at once to the results DataFrame\n",
    "        sheet_results = pd.DataFrame(period_results)\n",
    "        results_df = pd.concat([results_df, sheet_results], ignore_index=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results DataFrame with all needed columns\n",
    "results_df = pd.DataFrame(columns=[\"Sheet\", \"Period\", \"Inventory of item 1\", \"Produced for item 1\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_df = solve_MILP(data, sheet_name, results_df)\n",
    "\n",
    "results_df.to_csv(\"results_MILP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plant location reformulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the single-item lot-sizing problem, an alternative formulation for the current problem, also \n",
    "called plant location reformulation (PLRFIP), is obtained by replacing in the model (MiCLSP-STIP) the \n",
    "production variables ð‘¥ð‘–ð‘¡ by the variables ð‘¤ð‘ ð‘¡ ð‘– given by:\n",
    "\n",
    "Where ð‘¤ð‘ ð‘¡ ð‘– can be interpreted as the portion of demand of item ð‘– âˆˆ ð‘ƒ in period ð‘¡ âˆˆ ð» fulfilled by \n",
    "production in period ð‘  âˆˆ ð»,ð‘  â‰¤ ð‘¡. Write down this reformulation and check the validity of your \n",
    "proposed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_PLRF(data, sheet_name, results_df):\n",
    "\n",
    "    model=gp.Model(\"PLRF\")\n",
    "\n",
    "\n",
    "    #decisions variables\n",
    "\n",
    "    T=data.T\n",
    "    O=data.items\n",
    "\n",
    "    w=model.addVars(O+1, T+1, T+1, vtype=GRB.CONTINUOUS, lb=0, ub=1, name = \"w\" )#fraction of demand of item i produced in period s to satisfy period t\n",
    "    y=model.addVars(O+1, T+1, vtype=GRB.BINARY, name=\"y\") #produce or not for item i in period i\n",
    "\n",
    "    model.setObjective(\n",
    "        #setup cost\n",
    "        quicksum(quicksum( data.setup_cost[i, t] * y[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        #production cost, j is actual period and t in future period\n",
    "        quicksum(quicksum(quicksum(data.production_cost[i, s] * data.demand_forecast[i,t] * w[i, s, t] \n",
    "                          for t in range(s, T+1)) # Changed range\n",
    "                 for s in range(1, T+1))\n",
    "        for i in range(1, O+1))+\n",
    "        #holding cost, i per item\n",
    "        quicksum( quicksum(quicksum\n",
    "                           (sum(data.holding_cost[ i, t] for t in range(s, j)) * data.demand_forecast[i, j] * w[i, s, j] for j in range(s+1, T+1))\n",
    "                           for s in range(1, T+1)) for i in range(1, O+1)),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Each demand must be fully satisfied (like each customer must be served) for each item\n",
    "    for i in range(1, O+1):\n",
    "        for t in range(1, T+1):\n",
    "            model.addConstr( quicksum(w[i, s, t] for s in range(1, t+1)) == 1, name= f\"demand_{i}{t}\")\n",
    "            \n",
    "    #cannot produce any fraction of demand in period s is the variable y is 0, for item i\n",
    "    for i in range(1, O+1):\n",
    "        for t in range(1, T+1):\n",
    "            for s in range(1, t+1):\n",
    "                model.addConstr( w[i, s, t] <= y[i, s] )\n",
    "        \n",
    "    #still capacity constraints fossure\n",
    "    #constraint 3\n",
    "\n",
    "    for s in range(1, T+1):\n",
    "        model.addConstr(\n",
    "            quicksum(\n",
    "                # Production time: sum over all demands being produced in period s\n",
    "                sum(w[i, s, t] * data.demand_forecast[i, t] for t in range(s, T+1)) * data.item_requirements[i, 1] +\n",
    "                # Setup time\n",
    "                data.item_requirements[i, 2] * y[i, s]\n",
    "                for i in range(1, O+1)\n",
    "            ) <= data.capacity[s, 1],\n",
    "            name=f\"capacity_{s}\"\n",
    "        )\n",
    "        \n",
    "    \n",
    "    #constraint 4\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr( sum( w[i, t, s] for s in range(t, T+1) )-(quicksum(data.demand_forecast[i, q] for q in range(t, T+1))) * y[i, t]<=0)\n",
    "\n",
    "    \n",
    "    #solve\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "\n",
    "        print(\"\\noptimal solution found:\")\n",
    "\n",
    "        # Create a list to store all periods' results for this sheet\n",
    "        period_results = []\n",
    "        \n",
    "        # Collect results for each period\n",
    "        for t in range(1, T+1):\n",
    "            period_results.append({\n",
    "                \"Sheet\": sheet_name,\n",
    "                \"Period\": t,\n",
    "                \"Setup Decision\": y[1, t].X,\n",
    "                \"Production Quantity\": sum(w[2, t, j].X * data.demand_forecast[2, j] for j in range(t, T+1)),\n",
    "                \"Capacity Usage\": sum(sum(w[i, t, j].X * data.demand_forecast[i, j] * data.item_requirements[i, 1] + data.item_requirements[i, 2] * y[i,t].X  \n",
    "                                        for j in range(t, T+1)) \n",
    "                                    for i in range(1, O+1)) / data.capacity[t, 1],\n",
    "                \"Total Cost\": model.objVal\n",
    "            })\n",
    "        \n",
    "        sheet_results = pd.DataFrame(period_results)\n",
    "        results_df = pd.concat([ results_df, sheet_results ], ignore_index=False)\n",
    "\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize results DataFrame with all needed columns\n",
    "results_df = pd.DataFrame(columns=[\"Sheet\", \"Period\", \"Produced in the period for item 1\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_df = solve_PLRF(data, sheet_name, results_df)\n",
    "\n",
    "results_df.to_csv(\"results_PLRF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian relaxation of Constraint (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp \n",
    "from gurobipy import GRB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sheet_name):\n",
    "    file_path = \"CLSP+ST-instances Data-R.xlsx\"  \n",
    "    numbers = re.findall(r'\\d+', sheet_name)\n",
    "    number_items = int(numbers[0])\n",
    "    number_capacity = int(numbers[1])\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "\n",
    "    # Identify matrix boundaries manually or by searching keywords\n",
    "    demand_start = df[df[0] == \"Demand Forecast:\"].index[0] + 1\n",
    "    production_start = df[df[0] == \"Production Cost\"].index[0] + 1\n",
    "    holding_start = df[df[0] == \"Holding Cost\"].index[0] + 1\n",
    "    setup_start = df[df[0] == \"Setup Cost\"].index[0] + 1\n",
    "    capacity_start = df[df[0] == \"Capacity\"].index[0] + 1\n",
    "\n",
    "    # Extract matrices and remove first row and first column\n",
    "    demand_forecast = df.iloc[demand_start+1:production_start-2, 1:].reset_index(drop=True)\n",
    "    production_cost = df.iloc[production_start+1:holding_start-2, 1:].reset_index(drop=True)\n",
    "    holding_cost = df.iloc[holding_start+1:setup_start-2, 1:].reset_index(drop=True)\n",
    "    setup_cost = df.iloc[setup_start+1:setup_start+number_items+1, 1:].reset_index(drop=True)\n",
    "    capacity = df.iloc[capacity_start:capacity_start+number_capacity+1, 1:2].reset_index(drop=True)\n",
    "\n",
    "    UnitsOfCapacity_SupTime = df.iloc[setup_start+number_items+2:capacity_start-2, 1:3].reset_index(drop=True)\n",
    "    UnitsOfCapacity_SupTime.columns = UnitsOfCapacity_SupTime.iloc[0]\n",
    "    UnitsOfCapacity_SupTime = UnitsOfCapacity_SupTime[1:].reset_index(drop=True)\n",
    "    UnitsOfCapacity = UnitsOfCapacity_SupTime['UnitsOfCapacity']\n",
    "    SetupTime = UnitsOfCapacity_SupTime['SetupTime']\n",
    "\n",
    "    # Convert to numeric values\n",
    "    demand_forecast = demand_forecast.apply(pd.to_numeric, errors='coerce')\n",
    "    production_cost = production_cost.apply(pd.to_numeric, errors='coerce')\n",
    "    holding_cost = holding_cost.apply(pd.to_numeric, errors='coerce')\n",
    "    setup_cost = setup_cost.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    data = {}\n",
    "    data['Demand Forecast'] = demand_forecast\n",
    "    data['Production Cost'] = production_cost\n",
    "    data['Holding Cost'] = holding_cost\n",
    "    data['Setup Cost'] = setup_cost\n",
    "    data['UnitsOfCapacity'] = UnitsOfCapacity\n",
    "    data['SetupTime'] = SetupTime\n",
    "    data['Capacity'] = capacity\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('Data-20-12 (1)')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take constraint 3 as the hard constraint\n",
    "\n",
    "model = gp.Model(\"LR\")\n",
    "\n",
    "N, T = data['Demand Forecast'].shape\n",
    "\n",
    "d = np.array(data['Demand Forecast'])\n",
    "c = np.array(data['Production Cost'])\n",
    "h = np.array(data['Holding Cost'])\n",
    "f = np.array(data['Setup Cost'])\n",
    "r = np.array(data['UnitsOfCapacity'])\n",
    "k = np.array(data['Capacity']).flatten()\n",
    "tau = np.array(data['SetupTime'])\n",
    "\n",
    "mu = np.ones(T)\n",
    "dual_bounds = []\n",
    "best_dual_bound = float('-inf')\n",
    "norm = [np.linalg.norm(mu)]\n",
    "\n",
    "iteration = 0\n",
    "while iteration <= 2000:\n",
    "    iteration += 1\n",
    "    print(f'Iteration: {iteration}')\n",
    "    \n",
    "    y = model.addVars(N, T, vtype=GRB.BINARY, name=\"y\")\n",
    "    s = model.addVars(N, T, vtype=GRB.CONTINUOUS, lb=0, name=\"s\")\n",
    "    x = model.addVars(N, T, vtype=GRB.CONTINUOUS, lb=0, name=\"x\")\n",
    "\n",
    "    model.setObjective(\n",
    "        gp.quicksum(\n",
    "            gp.quicksum(\n",
    "                f[i, t] * y[i, t] +\n",
    "                c[i, t] * x[i, t] +\n",
    "                h[i, t] * s[i, t] +\n",
    "                mu[t] * (r[i] * x[i, t] + tau[i] * y[i, t])\n",
    "                for i in range(N)\n",
    "            ) for t in range(T)\n",
    "        ) - gp.quicksum(mu[t] * k[t] for t in range(T)), \n",
    "        GRB.MINIMIZE\n",
    "    )    \n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(N):\n",
    "            if t == 0:\n",
    "                model.addConstr(x[i, t] - s[i, t] == d[i, t])\n",
    "            else:\n",
    "                model.addConstr(s[i, t-1] + x[i, t] - s[i, t] == d[i, t])\n",
    "                \n",
    "            model.addConstr(x[i, t] - gp.quicksum(d[i, q] for q in range(t, T)) * y[i, t] <= 0)\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         model.addConstr(gp.quicksum(r[i]*x[i, t] + tau[i]*y[i, t] for i in range(N))  <= k[t])\n",
    "    \n",
    "\n",
    "    model.optimize()\n",
    "    \n",
    "    dual_obj = model.ObjVal\n",
    "    dual_bounds.append(dual_obj)\n",
    "    best_dual_bound = max(best_dual_bound, dual_obj)\n",
    "    norm.append(np.linalg.norm(mu))\n",
    "    \n",
    "    subgradient = np.array([\n",
    "        sum(r[i] * x[i, t].X + tau[i] * y[i, t].X for i in range(N)) - k[t]\n",
    "        for t in range(T)\n",
    "    ])\n",
    "    \n",
    "    if len(dual_bounds) > 100 and np.mean(dual_bounds[-10:]) - best_dual_bound < 0:\n",
    "        break\n",
    "        \n",
    "    mu = np.maximum(0, mu + subgradient/np.max(np.abs(subgradient)*10))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANTZIG WOLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benders' Decomposition\n",
    "\n",
    "Benders' Decomposition is a method for solving large-scale optimization problems with a specific block structure. It decomposes the problem into a **Master Problem (MP)** and a **Subproblem (SP)**, iteratively solving them to find the optimal solution.\n",
    "\n",
    "## Problem Decomposition\n",
    "\n",
    "- **Master Problem (MP):** A relaxed version of the original problem, focusing on a subset of the variables (often integer variables).\n",
    "- **Subproblem (SP):** A smaller problem obtained by fixing the variables of the Master Problem, often resulting in a linear program.\n",
    "\n",
    "## Algorithm Steps\n",
    "\n",
    "### **Initialization**\n",
    "Solve the Master Problem to obtain an initial solution \\( y_k \\).\n",
    "\n",
    "### **Iteration \\( k \\)**\n",
    "1. **Solve the Subproblem:**\n",
    "   - Fix the complicating variables \\( y \\) at the value \\( y_k \\) and solve the Subproblem.\n",
    "   - If the Subproblem is **optimal**, obtain its objective value \\( v(y_k) \\) and the dual variables \\( \\pi^k \\) associated with its constraints.\n",
    "   - If the Subproblem is **infeasible**, obtain a feasibility cut using Farkas' Lemma, characterized by \\( \\alpha^k \\) and \\( \\beta^k \\).\n",
    "\n",
    "2. **Generate Cut:**\n",
    "   - **Optimality Cut:**  \n",
    "     $$\n",
    "     \\theta \\geq v(y_k) + \\sum_i \\sum_t \\pi^k_t \\cdot (h_{it}(y_{it} - y^k_{it}))\n",
    "     $$\n",
    "   - **Feasibility Cut** (If Subproblem is infeasible):  \n",
    "     $$\n",
    "     \\sum_i \\sum_t \\alpha^k_t \\cdot h_{it} \\cdot y_{it} \\leq \\beta^k\n",
    "     $$\n",
    "   - Where:\n",
    "     - \\( h_{it} \\) represents how \\( y \\) affects the constraints in the Subproblem.\n",
    "     - \\( \\alpha^k_t \\) and \\( \\beta^k \\) are derived from Farkas' Lemma.\n",
    "\n",
    "3. **Add Cut to Master Problem:**\n",
    "   - The generated cut (optimality or feasibility) is added to the Master Problem to refine its solution space.\n",
    "\n",
    "4. **Solve Master Problem:**\n",
    "   - Solve the Master Problem, including the new cut, to obtain an updated solution \\( y_{k+1} \\) and a **lower bound (LB)** on the optimal solution.\n",
    "\n",
    "5. **Update Upper Bound (UB):**\n",
    "   - The upper bound (UB) is updated by taking the minimum of the current UB and the objective value of the Master Problem.\n",
    "\n",
    "6. **Convergence:**\n",
    "   - The algorithm terminates when the difference between the upper bound (UB) and the lower bound (LB) is less than or equal to a specified tolerance.\n",
    "\n",
    "## Variables\n",
    "\n",
    "- **y**: Complicating variables (variables in the Master Problem).  \n",
    "- **x**: Variables in the Subproblem.  \n",
    "- **theta**: Lower bound on the optimal value of the Subproblem.  \n",
    "- **pi^k**: Dual variables obtained from solving the Subproblem at iteration \\( k \\).  \n",
    "- **v(y_k)**: Optimal objective value of the Subproblem at iteration \\( k \\).  \n",
    "- **(alpha^k,beta^k)**: Variables from Farkas' Lemma.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "import time\n",
    "\n",
    "def solve_subproblem(data, T, O, demand, item_requirements, capacity_t, y_fixed):\n",
    "    sub_model = gp.Model(\"Subproblem\")\n",
    "    x_sub = sub_model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"x_sub\")\n",
    "    s_sub = sub_model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"s_sub\")\n",
    "    pi = sub_model.addVars(T + 1, lb=-GRB.INFINITY, name=\"pi\") # Dual variables for capacity constraints\n",
    "\n",
    "    obj_sub = quicksum(quicksum(data.production_cost[i, t] * x_sub[i, t] for i in range(1, O + 1)) for t in range(1, T + 1))\n",
    "    sub_model.setObjective(obj_sub, GRB.MINIMIZE)\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        for i in range(1, O + 1):\n",
    "            sub_model.addConstr(s_sub[i, t - 1] + x_sub[i, t] - s_sub[i, t] == demand[i, t], name=f\"inventory_{i}_{t}\")\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        sub_model.addConstr(quicksum(x_sub[i, t] * item_requirements[i, 1] for i in range(1, O + 1)) <= capacity_t[t, 1] - quicksum(item_requirements[i, 2] * y_fixed[i, t] for i in range(1, O + 1)), name=f\"capacity_{t}\")\n",
    "\n",
    "    for i in range(1, O + 1):\n",
    "        sub_model.addConstr(s_sub[i, 0] == 0, name=\"no_init_inv_{i}\")\n",
    "\n",
    "    sub_model.Params.OutputFlag = 0\n",
    "    sub_model.optimize()\n",
    "\n",
    "    if sub_model.Status == GRB.OPTIMAL or sub_model.Status == GRB.SUBOPTIMAL:\n",
    "        obj_val_sub = sub_model.ObjVal\n",
    "        pi_values = {t: pi[t].X for t in range(1, T + 1)}\n",
    "        return obj_val_sub, pi_values, True, None\n",
    "    elif sub_model.Status == GRB.INFEASIBLE:\n",
    "        # Get dual Farkas multipliers to generate a feasibility cut\n",
    "        infeas_constr = sub_model.getConstrs()[-T:] # Capacity constraints are the ones that might cause infeasibility\n",
    "        ray = sub_model.getAttr(\"FarkasDual\", infeas_constr)\n",
    "        return None, None, False, ray\n",
    "    else:\n",
    "        return None, None, False, None\n",
    "\n",
    "def solve_master_problem(data, T, O, cuts):\n",
    "    master_model = gp.Model(\"MasterProblem\")\n",
    "    y_master = master_model.addVars(O + 1, T + 1, vtype=GRB.BINARY, name=\"y_master\")\n",
    "    theta = master_model.addVar(lb=-GRB.INFINITY, name=\"theta\")\n",
    "\n",
    "    obj_master = quicksum(quicksum(data.setup_cost[i, t] * y_master[i, t] for i in range(1, O + 1)) for t in range(1, T + 1)) + theta\n",
    "    master_model.setObjective(obj_master, GRB.MINIMIZE)\n",
    "\n",
    "    for i, (cut_obj, cut_coeffs_y) in enumerate(cuts):\n",
    "        master_model.addConstr(theta >= cut_obj + quicksum(quicksum(cut_coeffs_y[i, t] * (y_master[i, t] - 0) for i in range(1, O + 1)) for t in range(1, T + 1)), name=f\"optimality_cut_{i}\")\n",
    "\n",
    "    master_model.Params.OutputFlag = 0\n",
    "    master_model.optimize()\n",
    "\n",
    "    if master_model.Status == GRB.OPTIMAL:\n",
    "        y_master_values = {(i, t): y_master[i, t].X for i in range(1, O + 1) for t in range(1, T + 1)}\n",
    "        lower_bound = master_model.ObjVal\n",
    "        return y_master_values, lower_bound, True\n",
    "    else:\n",
    "        return None, None, False\n",
    "\n",
    "def benders_decomposition(data, sheet_name, results_df, max_iterations=100, tolerance=1e-4):\n",
    "    start_time = time.time()\n",
    "    T = data.T\n",
    "    O = data.items\n",
    "    demand = data.demand_forecast\n",
    "    item_requirements = data.item_requirements\n",
    "    capacity = data.capacity\n",
    "\n",
    "    y_current = {(i, t): 0 for i in range(1, O + 1) for t in range(1, T + 1)}\n",
    "    lower_bound = -np.inf\n",
    "    upper_bound = np.inf\n",
    "    cuts = []\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iterations and upper_bound - lower_bound > tolerance:\n",
    "        iteration += 1\n",
    "        print(f\"\\nIteration {iteration} - Sheet: {sheet_name}\")\n",
    "        print(f\"Current Lower Bound: {lower_bound:.2f}, Current Upper Bound: {upper_bound:.2f}, Gap: {upper_bound - lower_bound:.2f}\")\n",
    "\n",
    "        sub_obj, pi_values, sub_optimal, infeas_ray = solve_subproblem(data, T, O, demand, item_requirements, capacity, y_current)\n",
    "\n",
    "        if sub_optimal:\n",
    "            setup_cost_current = sum(data.setup_cost[i, t] * y_current[i, t] for i in range(1, O + 1) for t in range(1, T + 1))\n",
    "            current_upper_bound = setup_cost_current + sub_obj\n",
    "            upper_bound = min(upper_bound, current_upper_bound)\n",
    "            print(f\"Subproblem Optimal. New Upper Bound: {upper_bound:.2f}\")\n",
    "\n",
    "            cut_objective = sub_obj - sum(capacity[t, 1] * pi_values[t] for t in range(1, T + 1))\n",
    "            cut_coefficients_y = {}\n",
    "            for i in range(1, O + 1):\n",
    "                for t in range(1, T + 1):\n",
    "                    cut_coefficients_y[i, t] = item_requirements[i, 2] * pi_values[t]\n",
    "            cuts.append((cut_objective, cut_coefficients_y))\n",
    "\n",
    "            y_next, next_lower_bound, master_optimal = solve_master_problem(data, T, O, cuts)\n",
    "            if master_optimal:\n",
    "                lower_bound = next_lower_bound\n",
    "                print(f\"Master Problem Solved. New Lower Bound: {lower_bound:.2f}, Number of Cuts: {len(cuts)}\")\n",
    "                y_current = y_next\n",
    "            else:\n",
    "                print(\"Master problem infeasible.\")\n",
    "                break\n",
    "\n",
    "        elif infeas_ray is not None:\n",
    "            print(\"Subproblem Infeasible. Generating feasibility cut.\")\n",
    "            # Formulate feasibility cut based on infeas_ray\n",
    "            feasibility_cut_coeffs_y = {}\n",
    "            feasibility_rhs = 0\n",
    "            for t, ray_val in enumerate(infeas_ray, start=1):\n",
    "                for i in range(1, O + 1):\n",
    "                    feasibility_cut_coeffs_y[i, t] = item_requirements[i, 2] * ray_val\n",
    "                    feasibility_rhs += capacity[t, 1] * ray_val # Should be <= 0\n",
    "\n",
    "            # Need to formulate the cut properly to exclude y_current\n",
    "            # This is a simplified placeholder; the actual form depends on the dual ray\n",
    "            cuts.append((feasibility_rhs, feasibility_cut_coeffs_y))\n",
    "\n",
    "            y_next, next_lower_bound, master_optimal = solve_master_problem(data, T, O, cuts)\n",
    "            if master_optimal:\n",
    "                lower_bound = next_lower_bound # Lower bound might not improve with feasibility cuts\n",
    "                print(f\"Master Problem Solved (after feasibility cut). Lower Bound: {lower_bound:.2f}, Number of Cuts: {len(cuts)}\")\n",
    "                y_current = y_next\n",
    "            else:\n",
    "                print(\"Master problem infeasible after feasibility cut.\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print(\"Subproblem status unknown.\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    computation_time = end_time - start_time\n",
    "    print(f\"\\nBenders' Decomposition finished in {computation_time:.2f} seconds.\")\n",
    "    print(f\"Benders' Decomposition Solution Value (Z_BD): {upper_bound if upper_bound != np.inf else 'Not converged'}\")\n",
    "    print(f\"Final Gap: {upper_bound - lower_bound if upper_bound != np.inf and lower_bound != -np.inf else 'Not converged'}\")\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{'Sheet': sheet_name, 'Z_BD': upper_bound if upper_bound != np.inf else None, 'Time_BD': computation_time, 'Gap_BD': upper_bound - lower_bound if upper_bound != np.inf and lower_bound != -np.inf else None, 'Iterations': iteration, 'Cuts': len(cuts)}])], ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_list=[\"Data-20-12 (2)\"]\n",
    "\n",
    "# Initialize results DataFrame for Benders'\n",
    "results_benders_df = pd.DataFrame(columns=[\"Sheet\", \"Z_BD\", \"Time_BD\", \"Gap_BD\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_benders_df = benders_decomposition(data, sheet_name, results_benders_df)\n",
    "\n",
    "results_benders_df.to_csv(\"results_Benders.csv\", index=False)\n",
    "\n",
    "print(\"\\nBenders' Decomposition results saved to results_Benders.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHALLENGE\n",
    "\n",
    "Reconsider the 6-periods capacitated single-item uncapacitated lot-sizing problem, and assume now \n",
    "that the demand in each period is normally distributed and follows the distribution N(mean = 100, sigma = 20). \n",
    "To approximately solve the recourse problem, we first start by discretizing the distribution of the \n",
    "random demand ð’…ð’• at the end of each period ð‘¡. We assume that ð’…ð’• takes the realizations (mean Â± ð’Œ*sigma) \n",
    "for ð‘˜ = 0,1.5,2.5! Approximate the probability corresponding to each realization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so at each period we know that with a certain prob mean+-k*signma will happen\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "mean=100\n",
    "sigma=20\n",
    "k=[0, 1.5, 2.5]\n",
    "\n",
    "i=1\n",
    "j=1\n",
    "demand=[0] * 6\n",
    "while i < 6:\n",
    "    if i<4:\n",
    "        #print(i)\n",
    "        demand[i] = mean - k[i-1] * sigma\n",
    "        #print(demand[i])\n",
    "    else:\n",
    "        demand[i] = mean + k[j] * sigma\n",
    "        #print(demand[i])\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "demand[1:5] = sorted(demand[1:5])\n",
    "\n",
    "for i in range (1, 6):\n",
    "    print(demand[i])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "data_points=[0]*6\n",
    "\n",
    "for i in range (1, 6):\n",
    "    data_points[i] = ( demand[i] - mean)/sigma\n",
    "\n",
    "data_points[0:4] = sorted(data_points[1:5])\n",
    "\n",
    "for i in range (0, 5):\n",
    "    print(data_points[i])\n",
    "\n",
    "\n",
    "prob = [0] * 5\n",
    "\n",
    "# Compute probabilities\n",
    "probabilities = [stats.norm.cdf( data_points[i], loc=mean, scale=sigma) for i in range (0, 5)]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(probabilities[i])\n",
    "\n",
    "\n",
    "interval_probs = [probabilities[i] - probabilities[i-1] for i in range(1, len(probabilities))]\n",
    "interval_probs.insert(0, probabilities[0])  # First interval probability\n",
    "\n",
    "# Print results\n",
    "print(\"Data Points:\", data_points)\n",
    "print(\"Probabilities:\", interval_probs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
