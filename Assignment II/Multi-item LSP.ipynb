{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  \n",
    "# ***Capacitated Lot-Sizing Problem with Setup Times (CLSP-ST)***\n",
    "### *Group7*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "\n",
    "\n",
    "class Production_data:\n",
    "    def __init__(self, number_of_periods, number_of_items, demand_forecast, production_cost, holding_cost, setup_cost, item_requirements , capacity):\n",
    "        self.T=number_of_periods\n",
    "        self.items=number_of_items\n",
    "        self.demand_forecast=np.array(demand_forecast)\n",
    "        self.production_cost=np.array(production_cost)\n",
    "        self.holding_cost=np.array(holding_cost)\n",
    "        self.setup_cost=np.array(setup_cost)\n",
    "        self.item_requirements=np.array(item_requirements)\n",
    "        self.capacity=np.array(capacity)\n",
    "\n",
    "file_name = \"CLSP+ST-instances Data-R.xlsx\"\n",
    "#file_name = \"prova2.xlsx\"\n",
    "\n",
    "xls = pd.ExcelFile(file_name)  # Read the whole file\n",
    "\n",
    "tables_keywords = [\"Demand Forecast:\", \"Production Cost\", \"Holding Cost\", \"Setup Cost\", \"UnitsOfCapacity\", \"Capacity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(xls, sheet_name):\n",
    "    tables_dict = {}\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    \n",
    "    # Define which column to check for each keyword\n",
    "    columns_to_check = {\n",
    "        \"Demand Forecast:\": 0,\n",
    "        \"Production Cost\": 0,\n",
    "        \"Holding Cost\": 0,\n",
    "        \"Setup Cost\": 0,\n",
    "        \"UnitsOfCapacity\": 1,  # Check the second column for this keyword (it also contains setup time(i,2))\n",
    "        \"Capacity\": 0\n",
    "    }\n",
    "    \n",
    "    # Iterate through the keywords to find each table\n",
    "    for keyword in tables_keywords:\n",
    "        column_idx = columns_to_check.get(keyword, 0)\n",
    "        \n",
    "        # Check in the specified column for the keyword\n",
    "        match = df[df.iloc[:, column_idx].astype(str).str.contains(keyword, na=False)]\n",
    "        \n",
    "        if not match.empty:\n",
    "            table_start_row = match.index[0] + 1\n",
    "            \n",
    "            # Find the end of the current table (next keyword or empty rows)\n",
    "            end_row = None\n",
    "            for next_keyword in tables_keywords:\n",
    "                if next_keyword != keyword:\n",
    "                    next_column_idx = columns_to_check.get(next_keyword, 0)\n",
    "                    next_match = df.loc[table_start_row:][df.loc[table_start_row:].iloc[:, next_column_idx].astype(str).str.contains(next_keyword, na=False)]\n",
    "                    if not next_match.empty:\n",
    "                        potential_end = next_match.index[0]\n",
    "                        if end_row is None or potential_end < end_row:\n",
    "                            end_row = potential_end\n",
    "            \n",
    "            # If no next keyword found, look for empty rows\n",
    "            if end_row is None:\n",
    "                for i in range(table_start_row, len(df)):\n",
    "                    # Check if row is empty or contains only NaN values\n",
    "                    if df.iloc[i].isna().all():\n",
    "                        end_row = i\n",
    "                        break\n",
    "            \n",
    "            # If still no end found, use the end of the dataframe\n",
    "            if end_row is None:\n",
    "                end_row = len(df)\n",
    "            \n",
    "            # Extract the table\n",
    "            table_df = df.iloc[table_start_row:end_row]\n",
    "            \n",
    "            # Remove completely empty rows\n",
    "            table_df = table_df.dropna(how='all')\n",
    "            \n",
    "            # Remove completely empty columns\n",
    "            table_df = table_df.dropna(axis=1, how='all')\n",
    "            \n",
    "            # Remove any remaining NaN values by filling with 0\n",
    "            table_df = table_df.fillna(0)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            table = table_df.to_numpy()\n",
    "            tables_dict[keyword] = table\n",
    "    \n",
    "    # Create an instance of Production_data class\n",
    "    production_data = Production_data(\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[1]-1,\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[0]-1,  \n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Production Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Holding Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Setup Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"UnitsOfCapacity\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Capacity\", np.zeros((1,1)))\n",
    "\n",
    "    )\n",
    "    \n",
    "    production_data.capacity = np.vstack([\n",
    "    np.zeros((1, production_data.capacity.shape[1]), dtype=production_data.capacity.dtype),production_data.capacity])\n",
    "\n",
    "    production_data.item_requirements = np.vstack([\n",
    "    np.zeros((1, production_data.item_requirements.shape[1]), dtype=production_data.item_requirements.dtype),production_data.item_requirements\n",
    "])\n",
    "    return production_data \n",
    "\n",
    "#data=read_data(xls, \"Data-20-12 (1)\")\n",
    "\n",
    "#print(data.T)\n",
    "#print(data.items)\n",
    "\n",
    "#print(data.demand_forecast)\n",
    "#print(data.holding_cost)\n",
    "#print(data.setup_cost)\n",
    "#print(data.capacity)\n",
    "#print(data.production_cost)\n",
    "\n",
    "#print(data.capacity[0, 1])\n",
    "#print(data.capacity[12, 1])\n",
    "#print(data.item_requirements)\n",
    "\n",
    "sheet_list=[\"Data-20-12 (1)\", \"Data-20-12 (2)\"]\n",
    "        #\"Data-20-24 (1)\", \"Data-20-24 (2)\"]  \"Data-100-24 (1)\", \"Data-100-24 (2)\", \"Data-200-24\"]\n",
    "\n",
    "#sheet_list=[\"Sheet1\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 MILP vs LP Solutions (Gurobi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***MILP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "\n",
    "def solve_MILP(data, sheet_name, results_df):\n",
    "\n",
    "    model=gp.Model(\"MiCLSP-ST\")\n",
    "\n",
    "    T=data.T\n",
    "    O=data.items\n",
    "\n",
    "    #DUMMY AT PERIOD 0?\n",
    "\n",
    "    #decision variables, constraint 5 and 6 added here\n",
    "    y=model.addVars(O+1, T+1, vtype=GRB.BINARY, name=\"y\" ) #produce of not for this item in this period\n",
    "    s=model.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"s\") #amount of inv of item i in period t\n",
    "    x=model.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"x\") #amount produced of item i in period t\n",
    "\n",
    "    model.setObjective(\n",
    "        quicksum(quicksum( data.setup_cost[i, t] * y[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        quicksum(quicksum( data.production_cost[i, t] * x[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        quicksum(quicksum( data.holding_cost[i, t] * s[i, t] for i in range(1, O+1) ) for t in range(1, T+1)),\n",
    "        GRB.MINIMIZE\n",
    "    )  \n",
    "\n",
    "\n",
    "    #constraint 2\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr(s[i, t-1]+x[i, t]-s[i, t]==data.demand_forecast[i, t])\n",
    "\n",
    "    \n",
    "\n",
    "    #constraint 3, this definitely works\n",
    "    for t in range(1, T+1):\n",
    "        print(data.capacity[t,1])\n",
    "        model.addConstr( quicksum( x[i, t]*data.item_requirements[i, 1] + data.item_requirements[i,2] * y[i,t] for i in range(1, O+1))<= data.capacity[t, 1])\n",
    "        \n",
    "    #constraint 4, this defintely ok\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr(x[i, t]-(quicksum(data.demand_forecast[i, q] for q in range(t, T+1))) * y[i, t]<=0)\n",
    "\n",
    "    #constraint 7, no initial inventory for all items, this definitely works\n",
    "    for i in range(1, O+1):\n",
    "        model.addConstr( s[i, 0] == 0, name=\"no init inv\") #lloks like this constrint is ok\n",
    "    \n",
    "    #solve the model\n",
    "    model.optimize()\n",
    "\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        print(\"\\noptimal solution found:\")\n",
    "        print(model.ObjVal)\n",
    "\n",
    "        # Create a list to store all periods' results for this sheet\n",
    "        period_results = []\n",
    "        \n",
    "        # Collect results for each period\n",
    "        for t in range(1, T+1):\n",
    "            period_results.append({\n",
    "                \"Sheet\": sheet_name,\n",
    "                \"Period\": t,\n",
    "                \"Inventory of item 1\": s[1, t].X,   # hard-coded for item 1 only\n",
    "                \"Produced for item 1\": x[1, t].X\n",
    "            })\n",
    "        \n",
    "        # Add all periods at once to the results DataFrame\n",
    "        sheet_results = pd.DataFrame(period_results)\n",
    "        results_df = pd.concat([results_df, sheet_results], ignore_index=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results DataFrame with all needed columns\n",
    "results_df = pd.DataFrame(columns=[\"Sheet\", \"Period\", \"Inventory of item 1\", \"Produced for item 1\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_df = solve_MILP(data, sheet_name, results_df)\n",
    "\n",
    "results_df.to_csv(\"results_MILP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***LP-relaxation vs MILP Results***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def solve_model(data, sheet_name, results_df, relaxation=False):\n",
    "    model = gp.Model(\"MiCLSP-ST\")\n",
    "    T = data.T\n",
    "    O = data.items\n",
    "\n",
    "    # Set silent mode\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "\n",
    "    # Variables\n",
    "    vtype = GRB.CONTINUOUS if relaxation else GRB.BINARY\n",
    "    y = model.addVars(O + 1, T + 1, vtype=vtype, name=\"y\")\n",
    "    s = model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"s\")\n",
    "    x = model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"x\")\n",
    "\n",
    "    # Objective\n",
    "    model.setObjective(\n",
    "        quicksum(data.setup_cost[i, t] * y[i, t] for i in range(1, O + 1) for t in range(1, T + 1)) +\n",
    "        quicksum(data.production_cost[i, t] * x[i, t] for i in range(1, O + 1) for t in range(1, T + 1)) +\n",
    "        quicksum(data.holding_cost[i, t] * s[i, t] for i in range(1, O + 1) for t in range(1, T + 1)),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    # Constraints\n",
    "    for t in range(1, T + 1):\n",
    "        for i in range(1, O + 1):\n",
    "            model.addConstr(s[i, t - 1] + x[i, t] - s[i, t] == data.demand_forecast[i, t])\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        model.addConstr(\n",
    "            quicksum(x[i, t] * data.item_requirements[i, 1] + data.item_requirements[i, 2] * y[i, t]\n",
    "                     for i in range(1, O + 1)) <= data.capacity[t, 1]\n",
    "        )\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        for i in range(1, O + 1):\n",
    "            model.addConstr(x[i, t] <= quicksum(data.demand_forecast[i, q] for q in range(t, T + 1)) * y[i, t])\n",
    "\n",
    "    for i in range(1, O + 1):\n",
    "        model.addConstr(s[i, 0] == 0)\n",
    "\n",
    "    # Solve and measure time\n",
    "    start_time = time.time()\n",
    "    model.optimize()\n",
    "    solve_time = time.time() - start_time\n",
    "\n",
    "    # Store results\n",
    "    if model.Status == GRB.OPTIMAL:\n",
    "        label = \"LP Relaxation\" if relaxation else \"MILP\"\n",
    "        objective = model.ObjVal\n",
    "\n",
    "        for t in range(1, T + 1):\n",
    "            new_row = pd.DataFrame([{\n",
    "                \"Sheet\": sheet_name,\n",
    "                \"Model Type\": label,\n",
    "                \"Period\": t,\n",
    "                \"Inventory of item 1\": s[1, t].X,\n",
    "                \"Produced for item 1\": x[1, t].X,\n",
    "                \"Objective Value\": objective,\n",
    "                \"Solve Time (s)\": solve_time\n",
    "            }])\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        return results_df, objective, solve_time\n",
    "\n",
    "    # If no optimal solution found, return NaNs\n",
    "    return results_df, float('nan'), float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(columns=[\"Sheet\", \"ZLP\", \"ZIP\", \"Time_LP\", \"Time_IP\"])\n",
    "results = pd.DataFrame(columns=[\"Sheet\", \"Model Type\", \"Period\", \"Inventory of item 1\", \"Produced for item 1\", \"Objective Value\", \"Solve Time (s)\"])\n",
    "\n",
    "for sheet in sheet_list:\n",
    "    print(f\"Processing {sheet}\")\n",
    "    data = read_data(xls, sheet)\n",
    "\n",
    "    # Solve MILP\n",
    "    results, ZIP, Time_IP = solve_model(data, sheet, results, relaxation=False)\n",
    "\n",
    "    # Solve LP Relaxation\n",
    "    results, ZLP, Time_LP = solve_model(data, sheet, results, relaxation=True)\n",
    "\n",
    "    summary_df = pd.concat([summary_df, pd.DataFrame([{\n",
    "        \"Sheet\": sheet,\n",
    "        \"ZLP\": ZLP,\n",
    "        \"ZIP\": ZIP,\n",
    "        \"Time_LP\": Time_LP,\n",
    "        \"Time_IP\": Time_IP\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "# Save results\n",
    "#results.to_csv(\"CLSP_detailed_results.csv\", index=False)\n",
    "summary_df.to_csv(\"MIP_vs_LP-relax_results.csv\", index=False)\n",
    "print(\"Saved detailed and summary results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plant location reformulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the single-item lot-sizing problem, an alternative formulation for the current problem, also \n",
    "called plant location reformulation (PLRFIP), is obtained by replacing in the model (MiCLSP-STIP) the \n",
    "production variables 𝑥𝑖𝑡 by the variables 𝑤𝑠𝑡 𝑖 given by:\n",
    "\n",
    "Where 𝑤𝑠𝑡 𝑖 can be interpreted as the portion of demand of item 𝑖 ∈ 𝑃 in period 𝑡 ∈ 𝐻 fulfilled by \n",
    "production in period 𝑠 ∈ 𝐻,𝑠 ≤ 𝑡. Write down this reformulation and check the validity of your \n",
    "proposed model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_PLRF(data, sheet_name, results_df):\n",
    "\n",
    "    model=gp.Model(\"PLRF\")\n",
    "\n",
    "\n",
    "    #decisions variables\n",
    "\n",
    "    T=data.T\n",
    "    O=data.items\n",
    "\n",
    "    w=model.addVars(O+1, T+1, T+1, vtype=GRB.CONTINUOUS, lb=0, ub=1, name = \"w\" )#fraction of demand of item i produced in period s to satisfy period t\n",
    "    y=model.addVars(O+1, T+1, vtype=GRB.BINARY, name=\"y\") #produce or not for item i in period i\n",
    "\n",
    "    model.setObjective(\n",
    "        #setup cost\n",
    "        quicksum(quicksum( data.setup_cost[i, t] * y[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        #production cost, j is actual period and t in future period\n",
    "        quicksum(quicksum(quicksum(data.production_cost[i, s] * data.demand_forecast[i,t] * w[i, s, t] \n",
    "                          for t in range(s, T+1)) # Changed range\n",
    "                 for s in range(1, T+1))\n",
    "        for i in range(1, O+1))+\n",
    "        #holding cost, i per item\n",
    "        quicksum( quicksum(quicksum\n",
    "                           (sum(data.holding_cost[ i, t] for t in range(s, j)) * data.demand_forecast[i, j] * w[i, s, j] for j in range(s+1, T+1))\n",
    "                           for s in range(1, T+1)) for i in range(1, O+1)),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Each demand must be fully satisfied (like each customer must be served) for each item\n",
    "    for i in range(1, O+1):\n",
    "        for t in range(1, T+1):\n",
    "            model.addConstr( quicksum(w[i, s, t] for s in range(1, t+1)) == 1, name= f\"demand_{i}{t}\")\n",
    "            \n",
    "    #cannot produce any fraction of demand in period s is the variable y is 0, for item i\n",
    "    for i in range(1, O+1):\n",
    "        for t in range(1, T+1):\n",
    "            for s in range(1, t+1):\n",
    "                model.addConstr( w[i, s, t] <= y[i, s] )\n",
    "        \n",
    "    #still capacity constraints fossure\n",
    "    #constraint 3\n",
    "\n",
    "    for s in range(1, T+1):\n",
    "        model.addConstr(\n",
    "            quicksum(\n",
    "                # Production time: sum over all demands being produced in period s\n",
    "                sum(w[i, s, t] * data.demand_forecast[i, t] for t in range(s, T+1)) * data.item_requirements[i, 1] +\n",
    "                # Setup time\n",
    "                data.item_requirements[i, 2] * y[i, s]\n",
    "                for i in range(1, O+1)\n",
    "            ) <= data.capacity[s, 1],\n",
    "            name=f\"capacity_{s}\"\n",
    "        )\n",
    "        \n",
    "    \n",
    "    #constraint 4\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            model.addConstr( sum( w[i, t, s] for s in range(t, T+1) )-(quicksum(data.demand_forecast[i, q] for q in range(t, T+1))) * y[i, t]<=0)\n",
    "\n",
    "    \n",
    "    #solve\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "\n",
    "        print(\"\\noptimal solution found:\")\n",
    "\n",
    "        # Create a list to store all periods' results for this sheet\n",
    "        period_results = []\n",
    "        \n",
    "        # Collect results for each period\n",
    "        for t in range(1, T+1):\n",
    "            period_results.append({\n",
    "                \"Sheet\": sheet_name,\n",
    "                \"Period\": t,\n",
    "                \"Setup Decision\": y[1, t].X,\n",
    "                \"Production Quantity\": sum(w[2, t, j].X * data.demand_forecast[2, j] for j in range(t, T+1)),\n",
    "                \"Capacity Usage\": sum(sum(w[i, t, j].X * data.demand_forecast[i, j] * data.item_requirements[i, 1] + data.item_requirements[i, 2] * y[i,t].X  \n",
    "                                        for j in range(t, T+1)) \n",
    "                                    for i in range(1, O+1)) / data.capacity[t, 1],\n",
    "                \"Total Cost\": model.objVal\n",
    "            })\n",
    "        \n",
    "        sheet_results = pd.DataFrame(period_results)\n",
    "        results_df = pd.concat([ results_df, sheet_results ], ignore_index=False)\n",
    "\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Academic license 2560044 - for non-commercial use only - registered to vi___@ugent.be\n",
      "Optimize a model with 2052 rows, 3822 columns and 8280 nonzeros\n",
      "Model fingerprint: 0x098c81b5\n",
      "Variable types: 3549 continuous, 273 integer (273 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+01, 3e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presolve removed 521 rows and 2082 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 1531 rows, 1740 columns, 5860 nonzeros\n",
      "Variable types: 1520 continuous, 220 integer (220 binary)\n",
      "Found heuristic solution: objective 104535.00000\n",
      "\n",
      "Root relaxation: objective 8.939710e+04, 1753 iterations, 0.04 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 89397.0955    0   16 104535.000 89397.0955  14.5%     -    0s\n",
      "H    0     0                    98834.000000 89397.0955  9.55%     -    0s\n",
      "H    0     0                    98499.000000 89397.0955  9.24%     -    0s\n",
      "H    0     0                    98369.000000 89397.0955  9.12%     -    0s\n",
      "     0     0 89403.4329    0   29 98369.0000 89403.4329  9.11%     -    0s\n",
      "     0     0 89407.2255    0   41 98369.0000 89407.2255  9.11%     -    0s\n",
      "     0     0 89408.7691    0   37 98369.0000 89408.7691  9.11%     -    0s\n",
      "     0     0 89409.0508    0   37 98369.0000 89409.0508  9.11%     -    0s\n",
      "     0     0 89410.1567    0   41 98369.0000 89410.1567  9.11%     -    0s\n",
      "H    0     0                    97302.000000 89410.2748  8.11%     -    0s\n",
      "H    0     0                    97009.000000 89410.2748  7.83%     -    0s\n",
      "     0     0 89410.7803    0   40 97009.0000 89410.7803  7.83%     -    0s\n",
      "     0     0 89410.8850    0   38 97009.0000 89410.8850  7.83%     -    0s\n",
      "     0     0 89410.8989    0   38 97009.0000 89410.8989  7.83%     -    0s\n",
      "     0     0 89411.8041    0   46 97009.0000 89411.8041  7.83%     -    0s\n",
      "     0     0 89412.3884    0   45 97009.0000 89412.3884  7.83%     -    0s\n",
      "     0     0 89412.7039    0   45 97009.0000 89412.7039  7.83%     -    0s\n",
      "     0     0 89412.7123    0   45 97009.0000 89412.7123  7.83%     -    0s\n",
      "     0     0 89414.3644    0   42 97009.0000 89414.3644  7.83%     -    0s\n",
      "H    0     0                    96792.000000 89414.5013  7.62%     -    0s\n",
      "     0     0 89415.9921    0   45 96792.0000 89415.9921  7.62%     -    0s\n",
      "     0     0 89416.1272    0   45 96792.0000 89416.1272  7.62%     -    0s\n",
      "     0     0 89416.1791    0   45 96792.0000 89416.1791  7.62%     -    0s\n",
      "     0     0 89416.1929    0   47 96792.0000 89416.1929  7.62%     -    0s\n",
      "     0     0 89417.0866    0   39 96792.0000 89417.0866  7.62%     -    0s\n",
      "     0     0 89417.4794    0   37 96792.0000 89417.4794  7.62%     -    0s\n",
      "     0     0 89417.6431    0   40 96792.0000 89417.6431  7.62%     -    0s\n",
      "     0     0 89417.7114    0   38 96792.0000 89417.7114  7.62%     -    0s\n",
      "     0     0 89417.7232    0   44 96792.0000 89417.7232  7.62%     -    0s\n",
      "     0     0 89418.1763    0   44 96792.0000 89418.1763  7.62%     -    0s\n",
      "H    0     0                    96729.000000 89418.2327  7.56%     -    0s\n",
      "H    0     0                    95763.000000 89418.2327  6.63%     -    0s\n",
      "H    0     0                    95626.000000 89418.2327  6.49%     -    0s\n",
      "     0     0 89418.5652    0   47 95626.0000 89418.5652  6.49%     -    0s\n",
      "     0     0 89418.6060    0   46 95626.0000 89418.6060  6.49%     -    0s\n",
      "     0     0 89418.6073    0   47 95626.0000 89418.6073  6.49%     -    0s\n",
      "     0     0 89418.7852    0   45 95626.0000 89418.7852  6.49%     -    0s\n",
      "     0     0 89419.0457    0   41 95626.0000 89419.0457  6.49%     -    0s\n",
      "     0     0 89419.0655    0   44 95626.0000 89419.0655  6.49%     -    0s\n",
      "     0     0 89419.3336    0   44 95626.0000 89419.3336  6.49%     -    0s\n",
      "     0     0 89419.3868    0   44 95626.0000 89419.3868  6.49%     -    0s\n",
      "H    0     2                    94932.000000 89419.3868  5.81%     -    0s\n",
      "     0     2 89419.3868    0   44 94932.0000 89419.3868  5.81%     -    0s\n",
      "H    1     4                    94815.000000 89419.4664  5.69%   0.0    0s\n",
      "H   34    52                    89571.000000 89422.9544  0.17%  29.4    0s\n",
      "H  247   249                    89524.000000 89422.9544  0.11%  33.9    0s\n",
      "H 1018   789                    89523.000000 89424.0558  0.11%  31.8    1s\n",
      "H 1027   787                    89522.000000 89424.0558  0.11%  31.8    1s\n",
      "H 1047   804                    89521.000000 89424.0558  0.11%  31.8    1s\n",
      "H 1945  1149                    89519.000000 89426.5076  0.10%  32.9    4s\n",
      "H 2289  1260                    89509.800000 89426.5076  0.09%  33.5    4s\n",
      "H 2310  1077                    89488.800000 89426.5076  0.07%  33.5    4s\n",
      "H 2809  1122                    89481.800000 89429.8025  0.06%  31.4    4s\n",
      "  2907  1164 89452.5556   36   13 89481.8000 89430.5317  0.06%  31.2    5s\n",
      "* 7733  2561              50    89469.000000 89440.1672  0.03%  27.8    8s\n",
      "  9860  2925 89465.7291   34    8 89469.0000 89443.1959  0.03%  27.2   10s\n",
      " 15644  3516 89462.4303   27   13 89469.0000 89448.8327  0.02%  26.5   15s\n",
      " 21364  3570 89458.6071   25   17 89469.0000 89452.8329  0.02%  25.9   20s\n",
      " 26686  2520     cutoff   31      89469.0000 89456.7223  0.01%  25.5   25s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  Cover: 2\n",
      "  Projected implied bound: 4\n",
      "  MIR: 96\n",
      "  Relax-and-lift: 1\n",
      "\n",
      "Explored 30358 nodes (765013 simplex iterations) in 28.24 seconds (18.08 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 89469 89481.8 89488.8 ... 89571\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.946900000000e+04, best bound 8.946051280101e+04, gap 0.0095%\n",
      "\n",
      "optimal solution found:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Academic license 2560044 - for non-commercial use only - registered to vi___@ugent.be\n",
      "Optimize a model with 2052 rows, 3822 columns and 8280 nonzeros\n",
      "Model fingerprint: 0xeffed8d2\n",
      "Variable types: 3549 continuous, 273 integer (273 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+05]\n",
      "  Objective range  [4e+01, 9e+05]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 6e+05]\n",
      "Presolve removed 575 rows and 2091 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 1477 rows, 1731 columns, 5777 nonzeros\n",
      "Variable types: 1516 continuous, 215 integer (215 binary)\n",
      "Found heuristic solution: objective 1.443455e+07\n",
      "\n",
      "Root relaxation: objective 1.432807e+07, 448 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1.4328e+07    0   10 1.4435e+07 1.4328e+07  0.74%     -    0s\n",
      "H    0     0                    1.441526e+07 1.4328e+07  0.60%     -    0s\n",
      "     0     0 1.4329e+07    0   10 1.4415e+07 1.4329e+07  0.60%     -    0s\n",
      "     0     0 1.4329e+07    0   10 1.4415e+07 1.4329e+07  0.60%     -    0s\n",
      "     0     0 1.4330e+07    0   10 1.4415e+07 1.4330e+07  0.59%     -    0s\n",
      "     0     0 1.4330e+07    0   11 1.4415e+07 1.4330e+07  0.59%     -    0s\n",
      "H    0     0                    1.441391e+07 1.4330e+07  0.59%     -    0s\n",
      "H    0     0                    1.433066e+07 1.4330e+07  0.01%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 2\n",
      "  Lift-and-project: 3\n",
      "  Cover: 1\n",
      "  MIR: 11\n",
      "  Flow cover: 4\n",
      "\n",
      "Explored 1 nodes (499 simplex iterations) in 0.37 seconds (0.06 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.43307e+07 1.44139e+07 1.44345e+07 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.433066189945e+07, best bound 1.432963133942e+07, gap 0.0072%\n",
      "\n",
      "optimal solution found:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize results DataFrame with all needed columns\n",
    "results_df = pd.DataFrame(columns=[\"Sheet\", \"Period\", \"Produced in the period for item 1\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_df = solve_PLRF(data, sheet_name, results_df)\n",
    "\n",
    "results_df.to_csv(\"results_PLRF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LP-relaxation (PLRFLP) of the (PLRFIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def solve_PLRF_models(data, sheet_name, results_df):\n",
    "    T = data.T\n",
    "    O = data.items\n",
    "\n",
    "    # Helper function to build and solve either the LP or IP version\n",
    "    def build_and_solve(relax=False):\n",
    "        model = gp.Model(\"PLRF_LP\" if relax else \"PLRF_IP\")\n",
    "        model.Params.OutputFlag = 0  # Suppress output\n",
    "\n",
    "        # Decision variables\n",
    "        w = model.addVars(O+1, T+1, T+1, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"w\")\n",
    "        y = model.addVars(O+1, T+1, vtype=GRB.CONTINUOUS if relax else GRB.BINARY, name=\"y\")\n",
    "\n",
    "        # Objective function\n",
    "        model.setObjective(\n",
    "            quicksum(quicksum(data.setup_cost[i, t] * y[i, t] for i in range(1, O+1)) for t in range(1, T+1)) +\n",
    "            quicksum(quicksum(quicksum(\n",
    "                data.production_cost[i, s] * data.demand_forecast[i, t] * w[i, s, t]\n",
    "                for t in range(s, T+1)) for s in range(1, T+1)) for i in range(1, O+1)) +\n",
    "            quicksum(quicksum(quicksum(\n",
    "                sum(data.holding_cost[i, t] for t in range(s, j)) * data.demand_forecast[i, j] * w[i, s, j]\n",
    "                for j in range(s+1, T+1)) for s in range(1, T+1)) for i in range(1, O+1)),\n",
    "            GRB.MINIMIZE\n",
    "        )\n",
    "\n",
    "        # Constraints\n",
    "        for i in range(1, O+1):\n",
    "            for t in range(1, T+1):\n",
    "                model.addConstr(quicksum(w[i, s, t] for s in range(1, t+1)) == 1)\n",
    "\n",
    "        for i in range(1, O+1):\n",
    "            for t in range(1, T+1):\n",
    "                for s in range(1, t+1):\n",
    "                    model.addConstr(w[i, s, t] <= y[i, s])\n",
    "\n",
    "        for s in range(1, T+1):\n",
    "            model.addConstr(\n",
    "                quicksum(\n",
    "                    sum(w[i, s, t] * data.demand_forecast[i, t] for t in range(s, T+1)) * data.item_requirements[i, 1] +\n",
    "                    data.item_requirements[i, 2] * y[i, s]\n",
    "                    for i in range(1, O+1)\n",
    "                ) <= data.capacity[s, 1]\n",
    "            )\n",
    "\n",
    "        for t in range(1, T+1):\n",
    "            for i in range(1, O+1):\n",
    "                model.addConstr(\n",
    "                    sum(w[i, t, s] for s in range(t, T+1)) - \n",
    "                    quicksum(data.demand_forecast[i, q] for q in range(t, T+1)) * y[i, t] <= 0\n",
    "                )\n",
    "\n",
    "        start = time.time()\n",
    "        model.optimize()\n",
    "        runtime = time.time() - start\n",
    "\n",
    "        return model.objVal if model.status == GRB.OPTIMAL else None, runtime\n",
    "\n",
    "    # Solve IP model\n",
    "    rfz_ip, time_ip = build_and_solve(relax=False)\n",
    "    \n",
    "    # Solve LP-relaxation\n",
    "    rfz_lp, time_lp = build_and_solve(relax=True)\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "        \"Sheet\": sheet_name,\n",
    "        \"RFZ_IP\": rfz_ip,\n",
    "        \"Time_IP (s)\": time_ip,\n",
    "        \"RFZ_LP\": rfz_lp,\n",
    "        \"Time_LP (s)\": time_lp\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data-20-12 (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\1752742818.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\irako\\AppData\\Local\\Temp\\ipykernel_4176\\3250259791.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Data-20-12 (2)\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(columns=[\"Sheet\", \"RFZLP\", \"RFZIP\", \"Time_LP\", \"Time_IP\"])\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Sheet\", \"RFZ_IP\", \"Time_IP (s)\", \"RFZ_LP\", \"Time_LP (s)\"\n",
    "])\n",
    "\n",
    "for sheet in sheet_list:\n",
    "    print(f\"Processing {sheet}\")\n",
    "    data = read_data(xls, sheet)\n",
    "\n",
    "    # Append both LP and IP results to results_df\n",
    "    results_df = solve_PLRF_models(data, sheet, results_df)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"results_PLRF_relax.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian relaxation of Constraint (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp \n",
    "from gurobipy import GRB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sheet_name):\n",
    "    file_path = \"CLSP+ST-instances Data-R.xlsx\"  \n",
    "    numbers = re.findall(r'\\d+', sheet_name)\n",
    "    number_items = int(numbers[0])\n",
    "    number_capacity = int(numbers[1])\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "\n",
    "    # Identify matrix boundaries manually or by searching keywords\n",
    "    demand_start = df[df[0] == \"Demand Forecast:\"].index[0] + 1\n",
    "    production_start = df[df[0] == \"Production Cost\"].index[0] + 1\n",
    "    holding_start = df[df[0] == \"Holding Cost\"].index[0] + 1\n",
    "    setup_start = df[df[0] == \"Setup Cost\"].index[0] + 1\n",
    "    capacity_start = df[df[0] == \"Capacity\"].index[0] + 1\n",
    "\n",
    "    # Extract matrices and remove first row and first column\n",
    "    demand_forecast = df.iloc[demand_start+1:production_start-2, 1:].reset_index(drop=True)\n",
    "    production_cost = df.iloc[production_start+1:holding_start-2, 1:].reset_index(drop=True)\n",
    "    holding_cost = df.iloc[holding_start+1:setup_start-2, 1:].reset_index(drop=True)\n",
    "    setup_cost = df.iloc[setup_start+1:setup_start+number_items+1, 1:].reset_index(drop=True)\n",
    "    capacity = df.iloc[capacity_start:capacity_start+number_capacity+1, 1:2].reset_index(drop=True)\n",
    "\n",
    "    UnitsOfCapacity_SupTime = df.iloc[setup_start+number_items+2:capacity_start-2, 1:3].reset_index(drop=True)\n",
    "    UnitsOfCapacity_SupTime.columns = UnitsOfCapacity_SupTime.iloc[0]\n",
    "    UnitsOfCapacity_SupTime = UnitsOfCapacity_SupTime[1:].reset_index(drop=True)\n",
    "    UnitsOfCapacity = UnitsOfCapacity_SupTime['UnitsOfCapacity']\n",
    "    SetupTime = UnitsOfCapacity_SupTime['SetupTime']\n",
    "\n",
    "    # Convert to numeric values\n",
    "    demand_forecast = demand_forecast.apply(pd.to_numeric, errors='coerce')\n",
    "    production_cost = production_cost.apply(pd.to_numeric, errors='coerce')\n",
    "    holding_cost = holding_cost.apply(pd.to_numeric, errors='coerce')\n",
    "    setup_cost = setup_cost.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    data = {}\n",
    "    data['Demand Forecast'] = demand_forecast\n",
    "    data['Production Cost'] = production_cost\n",
    "    data['Holding Cost'] = holding_cost\n",
    "    data['Setup Cost'] = setup_cost\n",
    "    data['UnitsOfCapacity'] = UnitsOfCapacity\n",
    "    data['SetupTime'] = SetupTime\n",
    "    data['Capacity'] = capacity\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('Data-20-12 (1)')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take constraint 3 as the hard constraint\n",
    "\n",
    "model = gp.Model(\"LR\")\n",
    "\n",
    "N, T = data['Demand Forecast'].shape\n",
    "\n",
    "d = np.array(data['Demand Forecast'])\n",
    "c = np.array(data['Production Cost'])\n",
    "h = np.array(data['Holding Cost'])\n",
    "f = np.array(data['Setup Cost'])\n",
    "r = np.array(data['UnitsOfCapacity'])\n",
    "k = np.array(data['Capacity']).flatten()\n",
    "tau = np.array(data['SetupTime'])\n",
    "\n",
    "mu = np.ones(T)\n",
    "dual_bounds = []\n",
    "best_dual_bound = float('-inf')\n",
    "norm = [np.linalg.norm(mu)]\n",
    "\n",
    "iteration = 0\n",
    "while iteration <= 2000:\n",
    "    iteration += 1\n",
    "    print(f'Iteration: {iteration}')\n",
    "    \n",
    "    y = model.addVars(N, T, vtype=GRB.BINARY, name=\"y\")\n",
    "    s = model.addVars(N, T, vtype=GRB.CONTINUOUS, lb=0, name=\"s\")\n",
    "    x = model.addVars(N, T, vtype=GRB.CONTINUOUS, lb=0, name=\"x\")\n",
    "\n",
    "    model.setObjective(\n",
    "        gp.quicksum(\n",
    "            gp.quicksum(\n",
    "                f[i, t] * y[i, t] +\n",
    "                c[i, t] * x[i, t] +\n",
    "                h[i, t] * s[i, t] +\n",
    "                mu[t] * (r[i] * x[i, t] + tau[i] * y[i, t])\n",
    "                for i in range(N)\n",
    "            ) for t in range(T)\n",
    "        ) - gp.quicksum(mu[t] * k[t] for t in range(T)), \n",
    "        GRB.MINIMIZE\n",
    "    )    \n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(N):\n",
    "            if t == 0:\n",
    "                model.addConstr(x[i, t] - s[i, t] == d[i, t])\n",
    "            else:\n",
    "                model.addConstr(s[i, t-1] + x[i, t] - s[i, t] == d[i, t])\n",
    "                \n",
    "            model.addConstr(x[i, t] - gp.quicksum(d[i, q] for q in range(t, T)) * y[i, t] <= 0)\n",
    "    \n",
    "#     for t in range(T):\n",
    "#         model.addConstr(gp.quicksum(r[i]*x[i, t] + tau[i]*y[i, t] for i in range(N))  <= k[t])\n",
    "    \n",
    "\n",
    "    model.optimize()\n",
    "    \n",
    "    dual_obj = model.ObjVal\n",
    "    dual_bounds.append(dual_obj)\n",
    "    best_dual_bound = max(best_dual_bound, dual_obj)\n",
    "    norm.append(np.linalg.norm(mu))\n",
    "    \n",
    "    subgradient = np.array([\n",
    "        sum(r[i] * x[i, t].X + tau[i] * y[i, t].X for i in range(N)) - k[t]\n",
    "        for t in range(T)\n",
    "    ])\n",
    "    \n",
    "    if len(dual_bounds) > 100 and np.mean(dual_bounds[-10:]) - best_dual_bound < 0:\n",
    "        break\n",
    "        \n",
    "    mu = np.maximum(0, mu + subgradient/np.max(np.abs(subgradient)*10))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANTZIG WOLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benders' Decomposition\n",
    "\n",
    "Benders' Decomposition is a method for solving large-scale optimization problems with a specific block structure. It decomposes the problem into a **Master Problem (MP)** and a **Subproblem (SP)**, iteratively solving them to find the optimal solution.\n",
    "\n",
    "## Problem Decomposition\n",
    "\n",
    "- **Master Problem (MP):** A relaxed version of the original problem, focusing on a subset of the variables (often integer variables).\n",
    "- **Subproblem (SP):** A smaller problem obtained by fixing the variables of the Master Problem, often resulting in a linear program.\n",
    "\n",
    "## Algorithm Steps\n",
    "\n",
    "### **Initialization**\n",
    "Solve the Master Problem to obtain an initial solution \\( y_k \\).\n",
    "\n",
    "### **Iteration \\( k \\)**\n",
    "1. **Solve the Subproblem:**\n",
    "   - Fix the complicating variables \\( y \\) at the value \\( y_k \\) and solve the Subproblem.\n",
    "   - If the Subproblem is **optimal**, obtain its objective value \\( v(y_k) \\) and the dual variables \\( \\pi^k \\) associated with its constraints.\n",
    "   - If the Subproblem is **infeasible**, obtain a feasibility cut using Farkas' Lemma, characterized by \\( \\alpha^k \\) and \\( \\beta^k \\).\n",
    "\n",
    "2. **Generate Cut:**\n",
    "   - **Optimality Cut:**  \n",
    "     $$\n",
    "     \\theta \\geq v(y_k) + \\sum_i \\sum_t \\pi^k_t \\cdot (h_{it}(y_{it} - y^k_{it}))\n",
    "     $$\n",
    "   - **Feasibility Cut** (If Subproblem is infeasible):  \n",
    "     $$\n",
    "     \\sum_i \\sum_t \\alpha^k_t \\cdot h_{it} \\cdot y_{it} \\leq \\beta^k\n",
    "     $$\n",
    "   - Where:\n",
    "     - \\( h_{it} \\) represents how \\( y \\) affects the constraints in the Subproblem.\n",
    "     - \\( \\alpha^k_t \\) and \\( \\beta^k \\) are derived from Farkas' Lemma.\n",
    "\n",
    "3. **Add Cut to Master Problem:**\n",
    "   - The generated cut (optimality or feasibility) is added to the Master Problem to refine its solution space.\n",
    "\n",
    "4. **Solve Master Problem:**\n",
    "   - Solve the Master Problem, including the new cut, to obtain an updated solution \\( y_{k+1} \\) and a **lower bound (LB)** on the optimal solution.\n",
    "\n",
    "5. **Update Upper Bound (UB):**\n",
    "   - The upper bound (UB) is updated by taking the minimum of the current UB and the objective value of the Master Problem.\n",
    "\n",
    "6. **Convergence:**\n",
    "   - The algorithm terminates when the difference between the upper bound (UB) and the lower bound (LB) is less than or equal to a specified tolerance.\n",
    "\n",
    "## Variables\n",
    "\n",
    "- **y**: Complicating variables (variables in the Master Problem).  \n",
    "- **x**: Variables in the Subproblem.  \n",
    "- **theta**: Lower bound on the optimal value of the Subproblem.  \n",
    "- **pi^k**: Dual variables obtained from solving the Subproblem at iteration \\( k \\).  \n",
    "- **v(y_k)**: Optimal objective value of the Subproblem at iteration \\( k \\).  \n",
    "- **(alpha^k,beta^k)**: Variables from Farkas' Lemma.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "import time\n",
    "\n",
    "def solve_subproblem(data, T, O, demand, item_requirements, capacity_t, y_fixed):\n",
    "    sub_model = gp.Model(\"Subproblem\")\n",
    "    x_sub = sub_model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"x_sub\")\n",
    "    s_sub = sub_model.addVars(O + 1, T + 1, vtype=GRB.CONTINUOUS, lb=0, name=\"s_sub\")\n",
    "    pi = sub_model.addVars(T + 1, lb=-GRB.INFINITY, name=\"pi\") # Dual variables for capacity constraints\n",
    "\n",
    "    obj_sub = quicksum(quicksum(data.production_cost[i, t] * x_sub[i, t] for i in range(1, O + 1)) for t in range(1, T + 1))\n",
    "    sub_model.setObjective(obj_sub, GRB.MINIMIZE)\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        for i in range(1, O + 1):\n",
    "            sub_model.addConstr(s_sub[i, t - 1] + x_sub[i, t] - s_sub[i, t] == demand[i, t], name=f\"inventory_{i}_{t}\")\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        sub_model.addConstr(quicksum(x_sub[i, t] * item_requirements[i, 1] for i in range(1, O + 1)) <= capacity_t[t, 1] - quicksum(item_requirements[i, 2] * y_fixed[i, t] for i in range(1, O + 1)), name=f\"capacity_{t}\")\n",
    "\n",
    "    for i in range(1, O + 1):\n",
    "        sub_model.addConstr(s_sub[i, 0] == 0, name=\"no_init_inv_{i}\")\n",
    "\n",
    "    sub_model.Params.OutputFlag = 0\n",
    "    sub_model.optimize()\n",
    "\n",
    "    if sub_model.Status == GRB.OPTIMAL or sub_model.Status == GRB.SUBOPTIMAL:\n",
    "        obj_val_sub = sub_model.ObjVal\n",
    "        pi_values = {t: pi[t].X for t in range(1, T + 1)}\n",
    "        return obj_val_sub, pi_values, True, None\n",
    "    elif sub_model.Status == GRB.INFEASIBLE:\n",
    "        # Get dual Farkas multipliers to generate a feasibility cut\n",
    "        infeas_constr = sub_model.getConstrs()[-T:] # Capacity constraints are the ones that might cause infeasibility\n",
    "        ray = sub_model.getAttr(\"FarkasDual\", infeas_constr)\n",
    "        return None, None, False, ray\n",
    "    else:\n",
    "        return None, None, False, None\n",
    "\n",
    "def solve_master_problem(data, T, O, cuts):\n",
    "    master_model = gp.Model(\"MasterProblem\")\n",
    "    y_master = master_model.addVars(O + 1, T + 1, vtype=GRB.BINARY, name=\"y_master\")\n",
    "    theta = master_model.addVar(lb=-GRB.INFINITY, name=\"theta\")\n",
    "\n",
    "    obj_master = quicksum(quicksum(data.setup_cost[i, t] * y_master[i, t] for i in range(1, O + 1)) for t in range(1, T + 1)) + theta\n",
    "    master_model.setObjective(obj_master, GRB.MINIMIZE)\n",
    "\n",
    "    for i, (cut_obj, cut_coeffs_y) in enumerate(cuts):\n",
    "        master_model.addConstr(theta >= cut_obj + quicksum(quicksum(cut_coeffs_y[i, t] * (y_master[i, t] - 0) for i in range(1, O + 1)) for t in range(1, T + 1)), name=f\"optimality_cut_{i}\")\n",
    "\n",
    "    master_model.Params.OutputFlag = 0\n",
    "    master_model.optimize()\n",
    "\n",
    "    if master_model.Status == GRB.OPTIMAL:\n",
    "        y_master_values = {(i, t): y_master[i, t].X for i in range(1, O + 1) for t in range(1, T + 1)}\n",
    "        lower_bound = master_model.ObjVal\n",
    "        return y_master_values, lower_bound, True\n",
    "    else:\n",
    "        return None, None, False\n",
    "\n",
    "def benders_decomposition(data, sheet_name, results_df, max_iterations=100, tolerance=1e-4):\n",
    "    start_time = time.time()\n",
    "    T = data.T\n",
    "    O = data.items\n",
    "    demand = data.demand_forecast\n",
    "    item_requirements = data.item_requirements\n",
    "    capacity = data.capacity\n",
    "\n",
    "    y_current = {(i, t): 0 for i in range(1, O + 1) for t in range(1, T + 1)}\n",
    "    lower_bound = -np.inf\n",
    "    upper_bound = np.inf\n",
    "    cuts = []\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iterations and upper_bound - lower_bound > tolerance:\n",
    "        iteration += 1\n",
    "        print(f\"\\nIteration {iteration} - Sheet: {sheet_name}\")\n",
    "        print(f\"Current Lower Bound: {lower_bound:.2f}, Current Upper Bound: {upper_bound:.2f}, Gap: {upper_bound - lower_bound:.2f}\")\n",
    "\n",
    "        sub_obj, pi_values, sub_optimal, infeas_ray = solve_subproblem(data, T, O, demand, item_requirements, capacity, y_current)\n",
    "\n",
    "        if sub_optimal:\n",
    "            setup_cost_current = sum(data.setup_cost[i, t] * y_current[i, t] for i in range(1, O + 1) for t in range(1, T + 1))\n",
    "            current_upper_bound = setup_cost_current + sub_obj\n",
    "            upper_bound = min(upper_bound, current_upper_bound)\n",
    "            print(f\"Subproblem Optimal. New Upper Bound: {upper_bound:.2f}\")\n",
    "\n",
    "            cut_objective = sub_obj - sum(capacity[t, 1] * pi_values[t] for t in range(1, T + 1))\n",
    "            cut_coefficients_y = {}\n",
    "            for i in range(1, O + 1):\n",
    "                for t in range(1, T + 1):\n",
    "                    cut_coefficients_y[i, t] = item_requirements[i, 2] * pi_values[t]\n",
    "            cuts.append((cut_objective, cut_coefficients_y))\n",
    "\n",
    "            y_next, next_lower_bound, master_optimal = solve_master_problem(data, T, O, cuts)\n",
    "            if master_optimal:\n",
    "                lower_bound = next_lower_bound\n",
    "                print(f\"Master Problem Solved. New Lower Bound: {lower_bound:.2f}, Number of Cuts: {len(cuts)}\")\n",
    "                y_current = y_next\n",
    "            else:\n",
    "                print(\"Master problem infeasible.\")\n",
    "                break\n",
    "\n",
    "        elif infeas_ray is not None:\n",
    "            print(\"Subproblem Infeasible. Generating feasibility cut.\")\n",
    "            # Formulate feasibility cut based on infeas_ray\n",
    "            feasibility_cut_coeffs_y = {}\n",
    "            feasibility_rhs = 0\n",
    "            for t, ray_val in enumerate(infeas_ray, start=1):\n",
    "                for i in range(1, O + 1):\n",
    "                    feasibility_cut_coeffs_y[i, t] = item_requirements[i, 2] * ray_val\n",
    "                    feasibility_rhs += capacity[t, 1] * ray_val # Should be <= 0\n",
    "\n",
    "            # Need to formulate the cut properly to exclude y_current\n",
    "            # This is a simplified placeholder; the actual form depends on the dual ray\n",
    "            cuts.append((feasibility_rhs, feasibility_cut_coeffs_y))\n",
    "\n",
    "            y_next, next_lower_bound, master_optimal = solve_master_problem(data, T, O, cuts)\n",
    "            if master_optimal:\n",
    "                lower_bound = next_lower_bound # Lower bound might not improve with feasibility cuts\n",
    "                print(f\"Master Problem Solved (after feasibility cut). Lower Bound: {lower_bound:.2f}, Number of Cuts: {len(cuts)}\")\n",
    "                y_current = y_next\n",
    "            else:\n",
    "                print(\"Master problem infeasible after feasibility cut.\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            print(\"Subproblem status unknown.\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    computation_time = end_time - start_time\n",
    "    print(f\"\\nBenders' Decomposition finished in {computation_time:.2f} seconds.\")\n",
    "    print(f\"Benders' Decomposition Solution Value (Z_BD): {upper_bound if upper_bound != np.inf else 'Not converged'}\")\n",
    "    print(f\"Final Gap: {upper_bound - lower_bound if upper_bound != np.inf and lower_bound != -np.inf else 'Not converged'}\")\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{'Sheet': sheet_name, 'Z_BD': upper_bound if upper_bound != np.inf else None, 'Time_BD': computation_time, 'Gap_BD': upper_bound - lower_bound if upper_bound != np.inf and lower_bound != -np.inf else None, 'Iterations': iteration, 'Cuts': len(cuts)}])], ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_list=[\"Data-20-12 (2)\"]\n",
    "\n",
    "# Initialize results DataFrame for Benders'\n",
    "results_benders_df = pd.DataFrame(columns=[\"Sheet\", \"Z_BD\", \"Time_BD\", \"Gap_BD\"])\n",
    "\n",
    "for sheet_name in sheet_list:\n",
    "    data = read_data(xls, sheet_name=sheet_name)\n",
    "    results_benders_df = benders_decomposition(data, sheet_name, results_benders_df)\n",
    "\n",
    "results_benders_df.to_csv(\"results_Benders.csv\", index=False)\n",
    "\n",
    "print(\"\\nBenders' Decomposition results saved to results_Benders.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHALLENGE\n",
    "\n",
    "Reconsider the 6-periods capacitated single-item uncapacitated lot-sizing problem, and assume now \n",
    "that the demand in each period is normally distributed and follows the distribution N(mean = 100, sigma = 20). \n",
    "To approximately solve the recourse problem, we first start by discretizing the distribution of the \n",
    "random demand 𝒅𝒕 at the end of each period 𝑡. We assume that 𝒅𝒕 takes the realizations (mean ± 𝒌*sigma) \n",
    "for 𝑘 = 0,1.5,2.5! Approximate the probability corresponding to each realization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so at each period we know that with a certain prob mean+-k*signma will happen\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "mean=100\n",
    "sigma=20\n",
    "k=[0, 1.5, 2.5]\n",
    "\n",
    "i=1\n",
    "j=1\n",
    "demand=[0] * 6\n",
    "while i < 6:\n",
    "    if i<4:\n",
    "        #print(i)\n",
    "        demand[i] = mean - k[i-1] * sigma\n",
    "        #print(demand[i])\n",
    "    else:\n",
    "        demand[i] = mean + k[j] * sigma\n",
    "        #print(demand[i])\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "demand[1:5] = sorted(demand[1:5])\n",
    "\n",
    "for i in range (1, 6):\n",
    "    print(demand[i])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "data_points=[0]*6\n",
    "\n",
    "for i in range (1, 6):\n",
    "    data_points[i] = ( demand[i] - mean)/sigma\n",
    "\n",
    "data_points[0:4] = sorted(data_points[1:5])\n",
    "\n",
    "for i in range (0, 5):\n",
    "    print(data_points[i])\n",
    "\n",
    "\n",
    "prob = [0] * 5\n",
    "\n",
    "# Compute probabilities\n",
    "probabilities = [stats.norm.cdf( data_points[i], loc=mean, scale=sigma) for i in range (0, 5)]\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(probabilities[i])\n",
    "\n",
    "\n",
    "interval_probs = [probabilities[i] - probabilities[i-1] for i in range(1, len(probabilities))]\n",
    "interval_probs.insert(0, probabilities[0])  # First interval probability\n",
    "\n",
    "# Print results\n",
    "print(\"Data Points:\", data_points)\n",
    "print(\"Probabilities:\", interval_probs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
