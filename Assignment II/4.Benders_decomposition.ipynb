{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a07bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "class Production_data:\n",
    "    def __init__(self, number_of_periods, number_of_items, demand_forecast, production_cost, holding_cost, setup_cost, item_requirements , capacity):\n",
    "        self.T=number_of_periods\n",
    "        self.items=number_of_items\n",
    "        self.demand_forecast=np.array(demand_forecast)\n",
    "        self.production_cost=np.array(production_cost)\n",
    "        self.holding_cost=np.array(holding_cost)\n",
    "        self.setup_cost=np.array(setup_cost)\n",
    "        self.item_requirements=np.array(item_requirements)\n",
    "        self.capacity=np.array(capacity)\n",
    "\n",
    "file_name = \"CLSP+ST-instances Data-R.xlsx\"\n",
    "#file_name = \"prova2.xlsx\"\n",
    "\n",
    "xls = pd.ExcelFile(file_name)  # Read the whole file\n",
    "\n",
    "tables_keywords = [\"Demand Forecast:\", \"Production Cost\", \"Holding Cost\", \"Setup Cost\", \"UnitsOfCapacity\", \"Capacity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c7d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_data(xls, sheet_name):\n",
    "    tables_dict = {}\n",
    "    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "    \n",
    "    # Define which column to check for each keyword\n",
    "    columns_to_check = {\n",
    "        \"Demand Forecast:\": 0,\n",
    "        \"Production Cost\": 0,\n",
    "        \"Holding Cost\": 0,\n",
    "        \"Setup Cost\": 0,\n",
    "        \"UnitsOfCapacity\": 1,  # Check the second column for this keyword\n",
    "        \"Capacity\": 0\n",
    "    }\n",
    "    \n",
    "    # Iterate through the keywords to find each table\n",
    "    for keyword in tables_keywords:\n",
    "        column_idx = columns_to_check.get(keyword, 0)\n",
    "        \n",
    "        # Check in the specified column for the keyword\n",
    "        match = df[df.iloc[:, column_idx].astype(str).str.contains(keyword, na=False)]\n",
    "        \n",
    "        if not match.empty:\n",
    "            table_start_row = match.index[0] + 1\n",
    "            \n",
    "            # Find the end of the current table (next keyword or empty rows)\n",
    "            end_row = None\n",
    "            for next_keyword in tables_keywords:\n",
    "                if next_keyword != keyword:\n",
    "                    next_column_idx = columns_to_check.get(next_keyword, 0)\n",
    "                    next_match = df.loc[table_start_row:][df.loc[table_start_row:].iloc[:, next_column_idx].astype(str).str.contains(next_keyword, na=False)]\n",
    "                    if not next_match.empty:\n",
    "                        potential_end = next_match.index[0]\n",
    "                        if end_row is None or potential_end < end_row:\n",
    "                            end_row = potential_end\n",
    "            \n",
    "            # If no next keyword found, look for empty rows\n",
    "            if end_row is None:\n",
    "                for i in range(table_start_row, len(df)):\n",
    "                    # Check if row is empty or contains only NaN values\n",
    "                    if df.iloc[i].isna().all():\n",
    "                        end_row = i\n",
    "                        break\n",
    "            \n",
    "            # If still no end found, use the end of the dataframe\n",
    "            if end_row is None:\n",
    "                end_row = len(df)\n",
    "            \n",
    "            # Extract the table\n",
    "            table_df = df.iloc[table_start_row:end_row]\n",
    "            \n",
    "            # Remove completely empty rows\n",
    "            table_df = table_df.dropna(how='all')\n",
    "            \n",
    "            # Remove completely empty columns\n",
    "            table_df = table_df.dropna(axis=1, how='all')\n",
    "            \n",
    "            # Remove any remaining NaN values by filling with 0\n",
    "            table_df = table_df.fillna(0)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            table = table_df.to_numpy()\n",
    "            tables_dict[keyword] = table\n",
    "    \n",
    "    # Create an instance of Production_data class\n",
    "    production_data = Production_data(\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[1]-1,\n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))).shape[0]-1,  \n",
    "        tables_dict.get(\"Demand Forecast:\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Production Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Holding Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Setup Cost\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"UnitsOfCapacity\", np.zeros((1,1))),  \n",
    "        tables_dict.get(\"Capacity\", np.zeros((1,1)))\n",
    "\n",
    "    )\n",
    "    \n",
    "    production_data.capacity = np.vstack([\n",
    "    np.zeros((1, production_data.capacity.shape[1]), dtype=production_data.capacity.dtype),production_data.capacity])\n",
    "\n",
    "    production_data.item_requirements = np.vstack([\n",
    "    np.zeros((1, production_data.item_requirements.shape[1]), dtype=production_data.item_requirements.dtype),production_data.item_requirements\n",
    "])\n",
    "    return production_data \n",
    "\n",
    "#data=read_data(xls, \"Data-20-12 (1)\")\n",
    "\n",
    "#print(data.T)\n",
    "#print(data.items)\n",
    "\n",
    "#print(data.demand_forecast)\n",
    "#print(data.holding_cost)\n",
    "#print(data.setup_cost)\n",
    "#print(data.capacity)\n",
    "#print(data.production_cost)\n",
    "\n",
    "#print(data.capacity[0, 1])\n",
    "#print(data.capacity[12, 1])\n",
    "#print(data.item_requirements)\n",
    "\n",
    "sheet_list=[\"Data-20-24 (1)\"]\n",
    "#[\"Data-20-12 (2)\"]#, \"Data-20-12 (2)\", \"Data-20-24 (1)\", \"Data-20-24 (2)\" , \"Data-100-24 (1)\", \"Data-100-24 (2)\",\n",
    "            \n",
    "\n",
    "#sheet_list=[\"Sheet1\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2708ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yit is the complicating variable, to fix, we fix it so then the problem becomes a simple LP \n",
    "#ok is gurobi the one that chooses the values for y\n",
    "#create dual and if dual feasible we add cut\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def Benders_decomposition(data, sheet_name, max_iterations):\n",
    "    # Initialize master problem\n",
    "    master = gp.Model(\"Benders Master Problem\")\n",
    "    \n",
    "    T = data.T\n",
    "    O = data.items\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    time_limit = 30 * 60  # 30 minutes\n",
    "    LBs = []\n",
    "    UBs = []\n",
    "\n",
    "    \n",
    "    # Master problem variables\n",
    "    y = master.addVars(O+1, T+1, vtype=GRB.BINARY, name=\"y\")  # setup decisions\n",
    "    theta = master.addVar(vtype=GRB.CONTINUOUS, lb=0, name=\"theta\")  # variable for optimality cuts\n",
    "\n",
    "    # Master problem objective\n",
    "    master.setObjective(\n",
    "        quicksum(quicksum(data.setup_cost[i, t] * y[i, t] for i in range(1, O+1)) for t in range(1, T+1)) +\n",
    "        theta,\n",
    "        GRB.MINIMIZE\n",
    "        \n",
    "    )\n",
    "    # Production limit constraints contribution\n",
    "    feas_cut_expr_prod = quicksum(\n",
    "                quicksum( (sum(data.demand_forecast[i, q] for q in range(t, T+1)) * y[i, t])\n",
    "                        for i in range(1, O+1)) #alright\n",
    "                for t in range(1, T+1) \n",
    "        )\n",
    "\n",
    "    # Flow constraints contribution\n",
    "    feas_cut_expr_flow = quicksum( quicksum(data.demand_forecast[i,t] for i in range(1,O+1)) for t in range(1,T+1))\n",
    "\n",
    "    master.addConstr(feas_cut_expr_flow<=feas_cut_expr_prod, name=\"initial cut\")\n",
    "\n",
    "\n",
    "    # Get initial y values from MILP solution\n",
    "    y_vals = np.zeros((O+1,T+1))\n",
    "\n",
    "    for i in range(1, O+1):\n",
    "        y_vals[i, 1]=1\n",
    "\n",
    "\n",
    "    UB=float(\"inf\")\n",
    "    LB=float(\"-inf\")\n",
    "\n",
    "    masterobj = []\n",
    "    fesibilitysubobj = []\n",
    "    \n",
    "    for iteration in range(1, max_iterations):\n",
    "\n",
    "        print(f\"\\nIteration {iteration}\")\n",
    "        \n",
    "        # Get Farkas certificates from feasibility subproblem\n",
    "        capacity_duals, prod_limit_duals, flow_duals, somma = solve_feasibility_subproblem(y_vals, data)\n",
    "    \n",
    "        if somma > 1e-6:  # If artificial variables are used, add feasibility cut\n",
    "            #subproblem infeasible, need to add feasibility cut\n",
    "            print(\"Subproblem is infeasible â†’ Adding feasibility cut\")\n",
    "                \n",
    "            # Capacity constraints contribution\n",
    "            feas_cut_expr_cap = quicksum(\n",
    "                +capacity_duals[t] * (data.capacity[t, 1] - quicksum(data.item_requirements[i, 2] * y[i, t]\n",
    "                for i in range(1, O+1))) #alright\n",
    "                for t in range(1, T+1)\n",
    "            )\n",
    "\n",
    "            # Production limit constraints contribution\n",
    "            feas_cut_expr_prod = quicksum(\n",
    "                quicksum(+prod_limit_duals[i, t] * \n",
    "                        (sum(data.demand_forecast[i, q] for q in range(t, T+1)) * y[i, t])\n",
    "                        for i in range(1, O+1)) #alright\n",
    "                for t in range(1, T+1)\n",
    "            )\n",
    "\n",
    "            # Flow constraints contribution\n",
    "            feas_cut_expr_flow = quicksum( quicksum(+flow_duals[i, t]*data.demand_forecast[i,t] for i in range(1,O+1)) for t in range(1,T+1)\n",
    "                    \n",
    "            )\n",
    "            # Add combined feasibility cut \n",
    "            master.addConstr(\n",
    "                feas_cut_expr_cap + feas_cut_expr_prod + feas_cut_expr_flow<= 0,\n",
    "                name=f\"feasibility_cut_{iteration}\"\n",
    "            )\n",
    "                \n",
    "            print(f\"Added feasibility cut in iteration {iteration}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Primal subproblem is optimal â†’ Adding optimality cut\")\n",
    "\n",
    "            subprob, x_vals, s_vals = create_and_solve_subprob(y_vals, data)\n",
    "\n",
    "            # Get dual values from optimal subproblem\n",
    "            capacity_duals = {}\n",
    "            prod_limit_duals = {}\n",
    "            \n",
    "            for t in range(1, T+1):\n",
    "                constr = subprob.getConstrByName(f\"capacity_{t}\")\n",
    "                capacity_duals[t] = constr.Pi\n",
    "                \n",
    "            for t in range(1, T+1):\n",
    "                for i in range(1, O+1):\n",
    "                    constr = subprob.getConstrByName(f\"prod_limit_{i}_{t}\")\n",
    "                    prod_limit_duals[i,t] = constr.Pi\n",
    "\n",
    "            # Add optimality cut\n",
    "            opt_cut_expr = quicksum(\n",
    "                +capacity_duals[t] * (data.capacity[t, 1] - quicksum(data.item_requirements[i, 2] * y[i, t]\n",
    "                for i in range(1, O+1)))\n",
    "                for t in range(1, T+1)\n",
    "            ) + quicksum(\n",
    "                quicksum(+prod_limit_duals[i, t] * \n",
    "                        (sum(data.demand_forecast[i, q] for q in range(t, T+1)) * y[i, t])\n",
    "                        for i in range(1, O+1))\n",
    "                for t in range(1, T+1)\n",
    "            )\n",
    "            + quicksum( quicksum(+flow_duals[i, t]*data.demand_forecast[i,t] for i in range(1,O+1)) for t in range(1,T+1))\n",
    "\n",
    "            \n",
    "            \n",
    "            master.addConstr(theta >= opt_cut_expr, name=f\"optimality_cut_{iteration}\")\n",
    "            print(f\"Added optimality cut in iteration {iteration}\")\n",
    "            \n",
    "            \n",
    "        # Solve updated master problem\n",
    "\n",
    "        remaining_time = max(0, time_limit - (time.time() - start_time))\n",
    "        master.setParam(\"TimeLimit\", remaining_time)\n",
    "        master.optimize()\n",
    "\n",
    "        \n",
    "        if master.status == GRB.OPTIMAL:\n",
    "            # Update y values\n",
    "            for t in range(1, T+1):\n",
    "                for i in range(1, O+1):\n",
    "                    y_vals[i][t] = y[i, t].X\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= time_limit:\n",
    "            print(\"Time limit reached. Stopping early.\")\n",
    "            break\n",
    "\n",
    "        LB=master.ObjVal\n",
    "        LBs.append(LB)\n",
    "\n",
    "        if somma<=1e-6 and subprob.Status == GRB.OPTIMAL:\n",
    "            UB=subprob.ObjVal\n",
    "        \n",
    "        if UB-LB<1:\n",
    "            print(\"Converged!!!!!\")\n",
    "            print(f\"UB: {master.ObjVal}\")\n",
    "            break\n",
    "\n",
    "\n",
    "    # After the loop\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(LBs, label='Lower Bound (LB)', marker='o')\n",
    "    plt.plot(UBs, label='Upper Bound (UB)', marker='x')\n",
    "    plt.xlabel(\"Iteration\", fontsize=14)\n",
    "    plt.ylabel(\"Objective Value\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"LB_UB_{sheet_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "    return y_vals,\n",
    "\n",
    "def create_and_solve_subprob(y_vals, data): #THIS IS P1, THE SUBPROBLEM\n",
    "    #IT IS HIGHLY POSSBILE THAT IT IS UNFEASIBLE FOR THE Ys PROVIDED\n",
    "\n",
    "    #THIS IS ALRIGHT\n",
    "\n",
    "    T=data.T\n",
    "    O=data.items\n",
    "\n",
    "    #now we need to do the subproblem\n",
    "    sub=gp.Model(\"Subproblem\")\n",
    "\n",
    "    s=sub.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"s\") #amount of inv of item i in period t\n",
    "    x=sub.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"x\") #amount produced of item i in period t\n",
    "\n",
    "\n",
    "    #this is P1\n",
    "    sub.setObjective(\n",
    "        quicksum(quicksum( data.production_cost[i, t] * x[i, t] for i in range(1, O+1) ) for t in range(1, T+1))+\n",
    "        quicksum(quicksum( data.holding_cost[i, t] * s[i, t] for i in range(1, O+1) ) for t in range(1, T+1)),\n",
    "    GRB.MINIMIZE\n",
    "    )  \n",
    "\n",
    "    #constraint 2\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            sub.addConstr( s[i, t-1] + x[i, t] - s[i, t] == data.demand_forecast[i, t], \n",
    "                         name=f\"flow_{i}_{t}\")\n",
    "\n",
    "    #constraint 3\n",
    "    for t in range(1, T+1):\n",
    "        sub.addConstr(quicksum(x[i, t] * data.item_requirements[i, 1] + data.item_requirements[i,2] * y_vals[i][t]   for i in range(1, O+1)) <= data.capacity[t, 1], \n",
    "             name=f\"capacity_{t}\")\n",
    "            \n",
    "    #constraint 4\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            sub.addConstr(x[i, t]-(quicksum(data.demand_forecast[i, q] \n",
    "                                          for q in range(t, T+1))) * y_vals[i][t] <= 0, \n",
    "                         name=f\"prod_limit_{i}_{t}\")\n",
    "\n",
    "    #constraint 7\n",
    "    for i in range(1, O+1):\n",
    "        sub.addConstr(s[i, 0] == 0, name=f\"init_inv_{i}\")\n",
    "        sub.addConstr(s[i, T] == 0, name=f\"fin_inv_{i}\")\n",
    "\n",
    "    \n",
    "    sub.optimize()\n",
    "        \n",
    "\n",
    "    return sub, x, s\n",
    "\n",
    "\n",
    "def solve_feasibility_subproblem(y_vals, data):\n",
    "    T = data.T\n",
    "    O = data.items\n",
    "\n",
    "    feas = gp.Model(\"Feasibility_Subproblem\")\n",
    "    # Variables\n",
    "    s = feas.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"s\")\n",
    "    x = feas.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"x\")\n",
    "\n",
    "    # Artificial variables for each constraint\n",
    "    a_flow = feas.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"a_flow\")\n",
    "    a_cap = feas.addVars(T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"a_cap\")\n",
    "    a_prod = feas.addVars(O+1, T+1, vtype=GRB.CONTINUOUS, lb=0, name=\"a_prod\")\n",
    "    a_init = feas.addVars(O+1, vtype=GRB.CONTINUOUS, lb=0, name=\"a_init\")\n",
    "    a_final = feas.addVars(O+1, vtype=GRB.CONTINUOUS, lb=0, name=\"a_final\")\n",
    "    \n",
    "    # Objective: minimize sum of artificial variables\n",
    "    feas.setObjective(\n",
    "        quicksum(a_flow[i, t] for i in range(1, O+1) for t in range(1, T+1)) +\n",
    "        quicksum(a_cap[t] for t in range(1, T+1)) +\n",
    "        quicksum(a_prod[i, t] for i in range(1, O+1) for t in range(1, T+1)) +\n",
    "        quicksum(a_init[i] + a_final[i] for i in range(1, O+1)),\n",
    "        GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    # Flow constraints with artificial variables\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            feas.addConstr(\n",
    "                s[i, t-1] + x[i, t] - s[i, t] + a_flow[i, t] == data.demand_forecast[i, t],\n",
    "                name=f\"flow_{i}_{t}\"\n",
    "            )\n",
    "\n",
    "    # Capacity constraints\n",
    "    for t in range(1, T+1):\n",
    "        feas.addConstr(\n",
    "            quicksum(x[i, t] * data.item_requirements[i, 1] + data.item_requirements[i, 2] * y_vals[i][t] for i in range(1, O+1)) +\n",
    "            a_cap[t] <= data.capacity[t, 1],\n",
    "            name=f\"capacity_{t}\"\n",
    "        )\n",
    "\n",
    "    # Production limit constraints\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            rhs = sum(data.demand_forecast[i, q] for q in range(t, T+1)) * y_vals[i][t]\n",
    "            feas.addConstr(\n",
    "                x[i, t] - rhs + a_prod[i, t] <= 0,\n",
    "                name=f\"prod_limit_{i}_{t}\"\n",
    "            )\n",
    "\n",
    "    # Inventory constraints\n",
    "    for i in range(1, O+1):\n",
    "        feas.addConstr(s[i, 0] + a_init[i] == 0, name=f\"init_inv_{i}\")\n",
    "        feas.addConstr(s[i, T] + a_final[i] == 0, name=f\"fin_inv_{i}\")\n",
    "\n",
    "    feas.optimize()\n",
    "\n",
    "    print(f\"Feasibility subproblem objective value: {feas.ObjVal}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Get Farkas duals from relaxed constraints\n",
    "    capacity_duals = {}\n",
    "    prod_limit_duals = {}\n",
    "    flow_duals = {}\n",
    "    \n",
    "    # Get duals for capacity constraints\n",
    "    for t in range(1, T+1):\n",
    "            constr = feas.getConstrByName(f\"capacity_{t}\")\n",
    "            capacity_duals[t] = constr.Pi\n",
    "            #print(f\"capacity duals: {capacity_duals[t]}\")\n",
    "\n",
    "        \n",
    "    # Get duals for production limit constraints\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            constr = feas.getConstrByName(f\"prod_limit_{i}_{t}\")\n",
    "            prod_limit_duals[i,t] = constr.Pi\n",
    "            #print(f\"prod limit duals: {prod_limit_duals[i, t]}\")\n",
    "            \n",
    "            \n",
    "    # Get duals for flow constraints\n",
    "    for t in range(1, T+1):\n",
    "        for i in range(1, O+1):\n",
    "            constr = feas.getConstrByName(f\"flow_{i}_{t}\")\n",
    "            flow_duals[i,t] = constr.Pi\n",
    "            #print(f\"flow duals: {flow_duals[i, t]}\")\n",
    "        \n",
    "    # Calculate sum of artificial variables for detecting infeasibility\n",
    "    flow_artificial=sum(sum(a_flow[i, t].X for i in range(1,O+1)) for t in range(1, T+1))\n",
    "    #print(f\"flow artificial variables sum: {flow_artificial}\")\n",
    "    capacity_artificial=sum(a_cap[t].X for t in range(1, T+1))\n",
    "    #print(f\"capacity artificial variables sum: {capacity_artificial}\")\n",
    "    prod_artificial=sum(sum(a_prod[i, t].X for i in range(1,O+1)) for t in range(1, T+1))\n",
    "    #print(f\"prod artificial variables sum: {prod_artificial}\")\n",
    "    \n",
    "\n",
    "    summ = flow_artificial+capacity_artificial+prod_artificial \n",
    "\n",
    "    return capacity_duals, prod_limit_duals, flow_duals, summ\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788ab40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (win64 - Windows 11.0 (22631.2))\n",
      "\n",
      "CPU model: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n",
      "C:\\Users\\ricca\\AppData\\Local\\Temp\\ipykernel_12144\\2548460570.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  table_df = table_df.fillna(0)\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGurobiError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sheet_name \u001b[38;5;129;01min\u001b[39;00m sheet_list:\n\u001b[32m      2\u001b[39m     data=read_data(xls, sheet_name)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mBenders_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mBenders_decomposition\u001b[39m\u001b[34m(data, sheet_name, max_iterations)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Get Farkas certificates from feasibility subproblem\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m capacity_duals, prod_limit_duals, flow_duals, somma = \u001b[43msolve_feasibility_subproblem\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m somma > \u001b[32m1e-6\u001b[39m:  \u001b[38;5;66;03m# If artificial variables are used, add feasibility cut\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m#subproblem infeasible, need to add feasibility cut\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSubproblem is infeasible â†’ Adding feasibility cut\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 289\u001b[39m, in \u001b[36msolve_feasibility_subproblem\u001b[39m\u001b[34m(y_vals, data)\u001b[39m\n\u001b[32m    286\u001b[39m     feas.addConstr(s[i, \u001b[32m0\u001b[39m] + a_init[i] == \u001b[32m0\u001b[39m, name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minit_inv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     feas.addConstr(s[i, T] + a_final[i] == \u001b[32m0\u001b[39m, name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfin_inv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[43mfeas\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFeasibility subproblem objective value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeas.ObjVal\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# Get Farkas duals from relaxed constraints\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\gurobipy\\\\_model.pyx:903\u001b[39m, in \u001b[36mgurobipy._model.Model.optimize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mGurobiError\u001b[39m: Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information"
     ]
    }
   ],
   "source": [
    "for sheet_name in sheet_list:\n",
    "    data=read_data(xls, sheet_name)\n",
    "    Benders_decomposition(data, sheet_name, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044403fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d4b136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
